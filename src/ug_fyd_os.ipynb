{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96887e9c",
   "metadata": {
    "id": "96887e9c"
   },
   "source": [
    "## Title: Deep Learning Solution for Automating the Processing of Observation Segmentation on Biodiversity Image Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CumBMey6F7sp",
   "metadata": {
    "id": "CumBMey6F7sp"
   },
   "source": [
    "This notebook is for the experiments in my final year project. My project will be utilizing this state-of-the-art deep learning model,CLIP to perform interpretable observation segmentation on biodiversity image data.\n",
    "\n",
    "Some useful markdown in Jupyter notebook: https://gtribello.github.io/mathNET/assets/notebook-writing.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NMau6thcGiWG",
   "metadata": {
    "id": "NMau6thcGiWG"
   },
   "source": [
    "# Setting Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fjhT4AyOnhnB",
   "metadata": {
    "id": "fjhT4AyOnhnB"
   },
   "source": [
    "## Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HK7B7AMFnhGp",
   "metadata": {
    "id": "HK7B7AMFnhGp"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PlrOD5LAnoyW",
   "metadata": {
    "id": "PlrOD5LAnoyW"
   },
   "outputs": [],
   "source": [
    "! ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QYHiPxhNnxIK",
   "metadata": {
    "id": "QYHiPxhNnxIK"
   },
   "outputs": [],
   "source": [
    "%cd /content/gdrive/My Drive/Colab Notebooks/data-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HwE7bClnRUrO",
   "metadata": {
    "id": "HwE7bClnRUrO"
   },
   "source": [
    "## CLIP Set Up "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2n2WmDFPuib4",
   "metadata": {
    "id": "2n2WmDFPuib4"
   },
   "source": [
    "Code below will install the clip package and its dependencies, and check if PyTorch 1.7.1 or later is installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "m7Az-mz7tc1_",
   "metadata": {
    "id": "m7Az-mz7tc1_"
   },
   "outputs": [],
   "source": [
    "! pip install ftfy regex tqdm\n",
    "! pip install git+https://github.com/openai/CLIP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LpR-j-esu_0y",
   "metadata": {
    "id": "LpR-j-esu_0y"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from pkg_resources import packaging\n",
    "\n",
    "print(\"Torch version:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vIjs1wf8vMKj",
   "metadata": {
    "id": "vIjs1wf8vMKj"
   },
   "source": [
    "**Loading & Evaluate the Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DD1qWvrovmAB",
   "metadata": {
    "id": "DD1qWvrovmAB"
   },
   "source": [
    "we can check all the available CLIP models by using clip.available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iSvUxQRevaBq",
   "metadata": {
    "id": "iSvUxQRevaBq"
   },
   "outputs": [],
   "source": [
    "import clip\n",
    "\n",
    "clip.available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kRcWqtQfJQZ7",
   "metadata": {
    "id": "kRcWqtQfJQZ7"
   },
   "outputs": [],
   "source": [
    "model, preprocess = clip.load(\"ViT-L/14@336px\")\n",
    "model.cuda().eval()\n",
    "input_resolution = model.visual.input_resolution\n",
    "context_length = model.context_length\n",
    "vocab_size = model.vocab_size\n",
    "\n",
    "print(\"Model parameters:\", f\"{np.sum([int(np.prod(p.shape)) for p in model.parameters()]):,}\")\n",
    "print(\"Input resolution:\", input_resolution)\n",
    "print(\"Context length:\", context_length)\n",
    "print(\"Vocab size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dzzh9qDTcxWf",
   "metadata": {
    "id": "dzzh9qDTcxWf"
   },
   "source": [
    "**Image Preprocessing in CLIP**\n",
    "\n",
    "- resize the input images and center-crop them to conform with the image resolution that the model expects.Before doing so, we will normalize the pixel intensity using the dataset mean and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tggo8Mi3g5xH",
   "metadata": {
    "id": "tggo8Mi3g5xH"
   },
   "outputs": [],
   "source": [
    "preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "M6L0aP9NhxOp",
   "metadata": {
    "id": "M6L0aP9NhxOp"
   },
   "source": [
    "**Text Preprocessing in CLIP**\n",
    "- We use a case-insensitive tokenizer, which can be invoked using clip.tokenize(). By default, the outputs are padded to become 77 tokens long, which is what the CLIP models expects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BwTw5-Dnh24k",
   "metadata": {
    "id": "BwTw5-Dnh24k"
   },
   "outputs": [],
   "source": [
    "clip.tokenize(\"hello world !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3gKEXt2BsXSo",
   "metadata": {
    "id": "3gKEXt2BsXSo"
   },
   "source": [
    "# Experiment 1 and Experiment 2 - Proof of Concept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9lbmNrjHWZP",
   "metadata": {
    "id": "c9lbmNrjHWZP"
   },
   "source": [
    "Proof of Concept - experiment with image-caption feature to assess its feasibility and potential impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nxtXEjz8D_cO",
   "metadata": {
    "id": "nxtXEjz8D_cO"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "import os\n",
    "from PIL import Image\n",
    "import array as arr \n",
    "from torchvision.datasets import CIFAR100\n",
    "\n",
    "\n",
    "resultList = []\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# model, preprocess = clip.load(\"RN50\", device=device)\n",
    "# model, preprocess = clip.load(\"RN101\", device=device)\n",
    "# model, preprocess = clip.load(\"RN50x4\", device=device)\n",
    "# model, preprocess = clip.load(\"RN50x16\", device=device)\n",
    "# model, preprocess = clip.load(\"RN50x64\", device=device)\n",
    "# model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "# model, preprocess = clip.load(\"ViT-B/16\", device=device)\n",
    "# model, preprocess = clip.load(\"ViT-L/14\", device=device)\n",
    "model, preprocess = clip.load(\"ViT-L/14@336px\", device=device)  #loading the ViT-L/14@336px model\n",
    "\n",
    "# download CIFAR100 dataset\n",
    "cifar100 = CIFAR100(root=os.path.expanduser(\"~/.cache\"), download=True, train=False)\n",
    "\n",
    "# loading image data\n",
    "source_path = '/content/gdrive/MyDrive/Colab Notebooks/data-1/imgs/'\n",
    "dir_contents = os.listdir(source_path) # returns list\n",
    "dir_contents.sort()\n",
    "num_pics = len(dir_contents)   # return the number of pictures in directory\n",
    "\n",
    "for i in range(num_pics):\n",
    "#Load and preprocess images and texts \n",
    "  print(\"\\nImage Title: \",dir_contents[i]);\n",
    "  image = preprocess(Image.open(source_path + dir_contents[i])).unsqueeze(0).to(device)\n",
    "  text_inputs = torch.cat([clip.tokenize(f\"a photo of a {c}\") for c in cifar100.classes]).to(device)\n",
    "\n",
    "# encode images and text via image encoder and transformer\n",
    "  with torch.no_grad():\n",
    "      image_features = model.encode_image(image)\n",
    "      text_features = model.encode_text(text_inputs)\n",
    "\n",
    "# compute the similarity between the images and captions, and return the most similar\n",
    "  image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "  text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "  similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "  values, indices = similarity[0].topk(1)\n",
    "\n",
    "# print the top prediction for each image                                   \n",
    "  print(\"\\nTop prediction:\\n\")\n",
    "  for value, index in zip(values, indices):\n",
    "      print(f\"{cifar100.classes[index]:>16s}: {100 * value.item():.2f}%\")\n",
    "      resultList.append(f\"{cifar100.classes[index]:>16s}\")\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HJx8SYBrJu5c",
   "metadata": {
    "id": "HJx8SYBrJu5c"
   },
   "source": [
    "Code below is trying with low-level captions to investigate the impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "W96P4AhxtsOt",
   "metadata": {
    "id": "W96P4AhxtsOt"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "import os\n",
    "from PIL import Image\n",
    "import array as arr \n",
    "\n",
    "resultList = []\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# model, preprocess = clip.load(\"RN50\", device=device)\n",
    "# model, preprocess = clip.load(\"RN101\", device=device)\n",
    "# model, preprocess = clip.load(\"RN50x4\", device=device)\n",
    "# model, preprocess = clip.load(\"RN50x16\", device=device)\n",
    "# model, preprocess = clip.load(\"RN50x64\", device=device)\n",
    "# model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "# model, preprocess = clip.load(\"ViT-B/16\", device=device)\n",
    "# model, preprocess = clip.load(\"ViT-L/14\", device=device)\n",
    "model, preprocess = clip.load(\"ViT-L/14@336px\", device=device)\n",
    "\n",
    "# load the captions from txt file into list\n",
    "with open('/content/gdrive/MyDrive/Colab Notebooks/lowlevelic.txt') as f:\n",
    "    image_descriptions = [line.rstrip() for line in f]\n",
    "\n",
    "source_path = '/content/gdrive/MyDrive/Colab Notebooks/data-1/imgs/'\n",
    "dir_contents = os.listdir(source_path) # returns list\n",
    "dir_contents.sort()\n",
    "num_pics = len(dir_contents)   # find number of pictures in directory\n",
    "\n",
    "for i in range(num_pics):\n",
    "#Load and preprocess images and texts\n",
    "  print(\"\\nImage Title: \",dir_contents[i]);\n",
    "  image = preprocess(Image.open(source_path + dir_contents[i])).unsqueeze(0).to(device)\n",
    "  text_inputs = torch.cat([clip.tokenize(f\" a photo of a {c}\") for c in image_descriptions]).to(device)\n",
    "\n",
    "  with torch.no_grad():\n",
    "      image_features = model.encode_image(image)\n",
    "      text_features = model.encode_text(text_inputs)\n",
    "\n",
    "  image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "  text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "  similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "  values, indices = similarity[0].topk(1)\n",
    "                                     \n",
    "  print(\"\\nTop predictions:\\n\")\n",
    "  for value, index in zip(values, indices):\n",
    "      print(f\"{image_descriptions[index]:>16s}: {100 * value.item():.2f}%\")\n",
    "      resultList.append(f\"{image_descriptions[index]:>16s}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Mxn3ArpMLc9t",
   "metadata": {
    "id": "Mxn3ArpMLc9t"
   },
   "source": [
    "Process the input image data based on the predictions into a list with 0, 1 which act as the boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vKsn2uUnX7pH",
   "metadata": {
    "id": "vKsn2uUnX7pH"
   },
   "outputs": [],
   "source": [
    "boundariesList = []\n",
    "\n",
    "x = len(resultList)\n",
    "print(f\"\\nNumber of Pics: {num_pics}\")\n",
    "print(f\"Length of List: {x}\" )  \n",
    "for i in range(num_pics):\n",
    "  if resultList[i] == resultList[x-1]:    #length count from 1, so need deduct 1\n",
    "    boundariesList.append(0)\n",
    "\n",
    "  elif(resultList[i] == resultList[i+1]):\n",
    "      boundariesList.append(0)\n",
    "\n",
    "  else:\n",
    "    boundariesList.append(1)\n",
    "\n",
    "\n",
    "for i in range(num_pics):\n",
    "   print(f\"{i+1}. {resultList[i]} {boundariesList[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "J7bxbhRXLlpb",
   "metadata": {
    "id": "J7bxbhRXLlpb"
   },
   "source": [
    "Processing the actual boundaries file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MlS4VoApkVUs",
   "metadata": {
    "id": "MlS4VoApkVUs"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load boundaries.txt file to act as true label\n",
    "boundaries_path_file = \"/content/gdrive/MyDrive/Colab Notebooks/data-1/Boundaries.txt\"\n",
    "boundaries_df = pd.read_csv(boundaries_path_file)\n",
    "bound_strings = boundaries_df.columns.tolist()\n",
    "num_bound = len(bound_strings)\n",
    "bound_int = []\n",
    "\n",
    "#convert string list to int list\n",
    "for i in range(0,len(bound_strings)):\n",
    "    bound_strings[i] = int(bound_strings[i])\n",
    "\n",
    "trueboundariesList = []\n",
    "\n",
    "\n",
    "for j in range(num_pics):                 # num_pics = 273\n",
    "  if j == bound_strings[num_bound -1]:    # -1 cause j start from 0, when 34 meet 34 is last\n",
    "      trueboundariesList.append(0)\n",
    "  elif any(j +1 == y  for y in bound_strings):\n",
    "    trueboundariesList.append(1)\n",
    "  else:\n",
    "     trueboundariesList.append(0)\n",
    "\n",
    "for i in range(num_pics):\n",
    "   print(f\"{i+1}. {trueboundariesList[i]}\")\n",
    "\n",
    "# there are 35 of boundaries detected, which match with the Boundaries.txt for data-1\n",
    "count = len([elem for elem in trueboundariesList if elem == 1])\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gOlN2SHML7hl",
   "metadata": {
    "id": "gOlN2SHML7hl"
   },
   "source": [
    "Calculate F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zRjOPFov5KqF",
   "metadata": {
    "id": "zRjOPFov5KqF"
   },
   "outputs": [],
   "source": [
    "# initializations\n",
    "# Compute TP, FP, TN, FN\n",
    "tp = 0; fp = 0; tn = 0; fn = 0;\n",
    "for bi in range(num_pics):\n",
    "    # If actual==1 and pred==1, increment true positives\n",
    "  if (trueboundariesList[bi] == 1) and (boundariesList[bi] == 1):\n",
    "    tp = tp + 1\n",
    "    # If actual==1 and pred==0, increment false negatives\n",
    "  if (trueboundariesList[bi] == 1) and (boundariesList[bi] == 0):\n",
    "    fn = fn + 1\n",
    "    # If actual==0 and pred==1, increment false positives\n",
    "  if (trueboundariesList[bi] == 0) and (boundariesList[bi] == 1):\n",
    "    fp = fp + 1\n",
    "    # If actual==0 and pred==0, increment true negatives\n",
    "  if (trueboundariesList[bi] == 0) and (boundariesList[bi] == 0):\n",
    "    tn = tn + 1\n",
    "\n",
    "# Display tp, fp, tn, fn\n",
    "print('True positives: ', tp)\n",
    "print('False positives: ', fp)\n",
    "print('True negatives: ', tn)\n",
    "print('False negatives: ', fn)\n",
    "\n",
    "# Compute precision and recall\n",
    "denom = (tp + fp)\n",
    "if denom > 0:\n",
    "    precision = tp / denom\n",
    "else:\n",
    "    precision = 0\n",
    "denom = (tp + fn)\n",
    "if denom > 0:\n",
    "    recall = tp / denom\n",
    "else:\n",
    "    recall = 0\n",
    "# Compute F1 score\n",
    "\n",
    "denom = (precision+recall)\n",
    "if denom > 0:\n",
    "    f1 = 2 * ((precision*recall)/denom)\n",
    "else:\n",
    "    f1 = 0\n",
    "# Return all metrics\n",
    "res = {\n",
    "        'tp': tp,\n",
    "        'fp': fp,\n",
    "        'tn': tn,\n",
    "        'fn': fn,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "}\n",
    "\n",
    "print(res)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4NA9zLWvdoY_",
   "metadata": {
    "id": "4NA9zLWvdoY_"
   },
   "source": [
    "# Experiment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4znFL9omhpB9",
   "metadata": {
    "id": "4znFL9omhpB9"
   },
   "source": [
    "## Alternative Approach 1: Boundaries Condition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HMJm97UDNO3y",
   "metadata": {
    "id": "HMJm97UDNO3y"
   },
   "source": [
    "Instead of just relying on the CLIP model to classify and make the prediction on boundaries, this experiment attempts to add one more criterion on top of CLIP prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "N1778qhlhy2y",
   "metadata": {
    "id": "N1778qhlhy2y"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "import os\n",
    "from PIL import Image\n",
    "import array as arr \n",
    "from torchvision.datasets import CIFAR100\n",
    "\n",
    "\n",
    "resultList = []\n",
    "diff_list = []\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model, preprocess = clip.load(\"ViT-L/14@336px\", device=device)\n",
    "\n",
    "cifar100 = CIFAR100(root=os.path.expanduser(\"~/.cache\"), download=True, train=False)\n",
    "\n",
    "source_path = '/content/gdrive/MyDrive/Colab Notebooks/data-1/imgs/'\n",
    "dir_contents = os.listdir(source_path) # returns list\n",
    "dir_contents.sort()\n",
    "num_pics = len(dir_contents)   # find number of pictures in directory\n",
    "\n",
    "for i in range(num_pics):\n",
    "#Load and prepare images\n",
    "  print(\"\\nImage Title: \",dir_contents[i]);\n",
    "  image = preprocess(Image.open(source_path + dir_contents[i])).unsqueeze(0).to(device)\n",
    "  text_inputs = torch.cat([clip.tokenize(f\"a photo of a {c}\") for c in cifar100.classes]).to(device)\n",
    "\n",
    "  with torch.no_grad():\n",
    "      image_features = model.encode_image(image)\n",
    "      text_features = model.encode_text(text_inputs)\n",
    "\n",
    "  image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "  text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "  similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "  values, indices = similarity[0].topk(3)\n",
    "  topOneCaption = values[0].tolist()\n",
    "  topTwoCaption = values[1].tolist()\n",
    "  #print(topOneCaption - topTwoCaption)\n",
    "  # subtract the top 1 and top 2 captions, and saved in diff_list\n",
    "  diff_list.append(topOneCaption - topTwoCaption)\n",
    "                                     \n",
    "  print(\"\\nTop predictions:\\n\")\n",
    "  for value, index in zip(values, indices):\n",
    "      print(f\"{cifar100.classes[index]:>16s}: {value.item():.2f}\")\n",
    "  \n",
    "  # store all the top 1 caption for each image in resultList\n",
    "  values, indices = similarity[0].topk(1)\n",
    "  for value, index in zip(values, indices):\n",
    "      resultList.append(f\"{cifar100.classes[index]:>16s}\")\n",
    "\n",
    "print(diff_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "C-MEOcD_PCmx",
   "metadata": {
    "id": "C-MEOcD_PCmx"
   },
   "source": [
    "Below is trying to access the top 5 captions for each image after combining ImageNet and CIFAR-100 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lTBu2wk86lHR",
   "metadata": {
    "id": "lTBu2wk86lHR"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "import os\n",
    "from PIL import Image\n",
    "import array as arr \n",
    "\n",
    "resultList = []\n",
    "diff_list = []\n",
    "top5List = []\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model, preprocess = clip.load(\"ViT-L/14@336px\", device=device)\n",
    "\n",
    "with open('/content/gdrive/MyDrive/Colab Notebooks/ImageCIFARTOP5.txt') as f:\n",
    "    image_descriptions = [line.rstrip() for line in f]\n",
    "\n",
    "source_path = '/content/gdrive/MyDrive/Colab Notebooks/data-1/imgs/'\n",
    "dir_contents = os.listdir(source_path) # returns list\n",
    "dir_contents.sort()\n",
    "num_pics = len(dir_contents)   # find number of pictures in directory\n",
    "\n",
    "for i in range(num_pics):\n",
    "#Load and prepare images\n",
    "  print(\"\\nImage Title: \",dir_contents[i]);\n",
    "  image = preprocess(Image.open(source_path + dir_contents[i])).unsqueeze(0).to(device)\n",
    "  text_inputs = torch.cat([clip.tokenize(f\"a photo of a {c}\") for c in image_descriptions]).to(device)\n",
    "\n",
    "  with torch.no_grad():\n",
    "      image_features = model.encode_image(image)\n",
    "      text_features = model.encode_text(text_inputs)\n",
    "\n",
    "  image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "  text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "  similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "  values, indices = similarity[0].topk(5)\n",
    "  topOneCaption = values[0].tolist()\n",
    "  topTwoCaption = values[1].tolist()\n",
    "  diff_list.append(topOneCaption - topTwoCaption)\n",
    "                                     \n",
    "                                     \n",
    "  print(\"\\nTop predictions:\\n\")\n",
    "  for value, index in zip(values, indices):\n",
    "      print(f\"{image_descriptions[index]:>16s}: {value.item():.4f}\")\n",
    "      # top5List will save all the top 5 captions results\n",
    "      #top5List.append(f\"{image_descriptions[index]:>16s}\")\n",
    "  \n",
    "  # store the index which is top 1 caption for result List to save\n",
    "  values, indices = similarity[0].topk(1)\n",
    "  for value, index in zip(values, indices):\n",
    "      resultList.append(f\"{image_descriptions[index]:>16s}\")\n",
    "\n",
    "#print(top5List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2es8WodAJaPE",
   "metadata": {
    "id": "2es8WodAJaPE"
   },
   "outputs": [],
   "source": [
    "# Union of top-5 classes of CIFAR and Image Net (can ignore if not collecting union of captions)\n",
    "# removed duplication\n",
    "top5List = list(dict.fromkeys(top5List))\n",
    "top5List\n",
    "len(top5List)\n",
    "#for x in range(len(top5List)):\n",
    "  #print(top5List(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9qBCkO53QDY0",
   "metadata": {
    "id": "9qBCkO53QDY0"
   },
   "source": [
    "Process the input image data into a list with 0, 1 act as the boundaries, also used to find the best threshold value for o and p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wQbWSUrqiJGj",
   "metadata": {
    "id": "wQbWSUrqiJGj"
   },
   "outputs": [],
   "source": [
    "# process the input image data into a list with 0, 1 act as the boundaries\n",
    "\n",
    "#o = 0.00\n",
    "#p = 0.00\n",
    "\n",
    "#diffO = []\n",
    "#diffF1 = []\n",
    "\n",
    "#while o <= 1.00:\n",
    "\n",
    "boundariesList = []\n",
    "\n",
    "x = len(resultList)\n",
    "#print(f\"\\nNumber of Pics: {num_pics}\")\n",
    "#print(f\"Length of List: {x}\" )  \n",
    "for i in range(num_pics):\n",
    "\n",
    "  if resultList[i] == resultList[x-1]:    #length count from 1, so need deduct 1\n",
    "    boundariesList.append(0)\n",
    "    #print(f\"{i+1}. {resultList[i]} 0\")\n",
    "  elif(resultList[i] == resultList[i+1] and (abs(diff_list[i] - diff_list[i+1])) <= 0.95): \n",
    "      boundariesList.append(0)\n",
    "      #same text but if similarity too high then boundary\n",
    "  elif(resultList[i] == resultList[i+1] and (abs(diff_list[i] - diff_list[i+1])) >= 0.95):\n",
    "      boundariesList.append(1)\n",
    "    #print(f\"{i+1}. {resultList[i]} 0\")\n",
    "  elif(resultList[i] != resultList[i+1] and (abs(diff_list[i] - diff_list[i+1])) >= 0.35):\n",
    "      boundariesList.append(1) \n",
    "  else:\n",
    "    boundariesList.append(0)\n",
    "\n",
    "#for i in range(num_pics):\n",
    "#    print(f\"{i+1}. {resultList[i]}    {diff_list[i]}      {boundariesList[i]}\")\n",
    "\n",
    "##############################\n",
    "# Calculating F1-score\n",
    "tp = 0; fp = 0; tn = 0; fn = 0;\n",
    "for bi in range(num_pics):\n",
    "    # If actual==1 and pred==1, increment true positives\n",
    "  if (trueboundariesList[bi] == 1) and (boundariesList[bi] == 1):\n",
    "    tp = tp + 1\n",
    "    # If actual==1 and pred==0, increment false negatives\n",
    "  if (trueboundariesList[bi] == 1) and (boundariesList[bi] == 0):\n",
    "    fn = fn + 1\n",
    "    # If actual==0 and pred==1, increment false positives\n",
    "  if (trueboundariesList[bi] == 0) and (boundariesList[bi] == 1):\n",
    "    fp = fp + 1\n",
    "    # If actual==0 and pred==0, increment true negatives\n",
    "  if (trueboundariesList[bi] == 0) and (boundariesList[bi] == 0):\n",
    "    tn = tn + 1\n",
    "\n",
    "\n",
    "# Compute precision and recall\n",
    "denom = (tp + fp)\n",
    "if denom > 0:\n",
    "    precision = tp / denom\n",
    "else:\n",
    "    precision = 0\n",
    "denom = (tp + fn)\n",
    "if denom > 0:\n",
    "    recall = tp / denom\n",
    "else:\n",
    "    recall = 0\n",
    "\n",
    "denom = (precision+recall)\n",
    "if denom > 0:\n",
    "    f1 = 2 * ((precision*recall)/denom)\n",
    "else:\n",
    "    f1 = 0\n",
    "# Return all metrics\n",
    "res = {\n",
    "        'tp': tp,\n",
    "        'fp': fp,\n",
    "        'tn': tn,\n",
    "        'fn': fn,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "}\n",
    "#diffO.append(o)\n",
    "#diffF1.append(res['f1'])\n",
    "#o += 0.05\n",
    "\n",
    "#print(diffO)\n",
    "print(res)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5L91B53YQn7c",
   "metadata": {
    "id": "5L91B53YQn7c"
   },
   "source": [
    "Utilising matplotlib to plot out the graph for for relationship between threshold and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iZQM_2RVDk76",
   "metadata": {
    "id": "iZQM_2RVDk76"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(diffO, diffF1)\n",
    "plt.xlabel(\"Diff_value (O)\")\n",
    "plt.ylabel(\"F1-score\")\n",
    "plt.xlim(0, 1.00)\n",
    "plt.ylim(0, 1.00)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YWNq65v2HGha",
   "metadata": {
    "id": "YWNq65v2HGha"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(diffO, diffF1)\n",
    "plt.xlabel(\"Diff_value (P)\")\n",
    "plt.ylabel(\"F1-score\")\n",
    "plt.xlim(0, 1.00)\n",
    "plt.ylim(0, 1.00)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ncNiKccyiOay",
   "metadata": {
    "id": "ncNiKccyiOay"
   },
   "outputs": [],
   "source": [
    "# Processing the actual boundaries file\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "boundaries_path_file = \"/content/gdrive/MyDrive/Colab Notebooks/data-1/Boundaries.txt\"\n",
    "boundaries_df = pd.read_csv(boundaries_path_file)\n",
    "bound_strings = boundaries_df.columns.tolist()\n",
    "num_bound = len(bound_strings)\n",
    "bound_int = []\n",
    "\n",
    "#convert string list to int list\n",
    "for i in range(0,len(bound_strings)):\n",
    "    bound_strings[i] = int(bound_strings[i])\n",
    "\n",
    "trueboundariesList = []\n",
    "\n",
    "\n",
    "for j in range(num_pics):                 # num_pics = 273\n",
    "  if j == bound_strings[num_bound -1]:    # -1 cause j start from 0, when 34 meet 34 is last\n",
    "      trueboundariesList.append(0)\n",
    "  elif any(j +1 == y  for y in bound_strings):\n",
    "    trueboundariesList.append(1)\n",
    "  else:\n",
    "     trueboundariesList.append(0)\n",
    "\n",
    "for i in range(num_pics):\n",
    "   print(f\"{i+1}. {trueboundariesList[i]}\")\n",
    "\n",
    "# there are 35 of boundaries detected, which match with the Boundaries.txt for data-1\n",
    "count = len([elem for elem in trueboundariesList if elem == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8kHqF1aHiZv6",
   "metadata": {
    "id": "8kHqF1aHiZv6"
   },
   "outputs": [],
   "source": [
    "# Calculate F-1 \n",
    "\n",
    "# initializations\n",
    "# Compute TP, FP, TN, FN\n",
    "tp = 0; fp = 0; tn = 0; fn = 0;\n",
    "for bi in range(num_pics):\n",
    "    # If actual==1 and pred==1, increment true positives\n",
    "  if (trueboundariesList[bi] == 1) and (boundariesList[bi] == 1):\n",
    "    tp = tp + 1\n",
    "    # If actual==1 and pred==0, increment false negatives\n",
    "  if (trueboundariesList[bi] == 1) and (boundariesList[bi] == 0):\n",
    "    fn = fn + 1\n",
    "    # If actual==0 and pred==1, increment false positives\n",
    "  if (trueboundariesList[bi] == 0) and (boundariesList[bi] == 1):\n",
    "    fp = fp + 1\n",
    "    # If actual==0 and pred==0, increment true negatives\n",
    "  if (trueboundariesList[bi] == 0) and (boundariesList[bi] == 0):\n",
    "    tn = tn + 1\n",
    "\n",
    "# Display tp, fp, tn, fn\n",
    "print('True positives: ', tp)\n",
    "print('False positives: ', fp)\n",
    "print('True negatives: ', tn)\n",
    "print('False negatives: ', fn)\n",
    "\n",
    "# Compute precision and recall\n",
    "denom = (tp + fp)\n",
    "if denom > 0:\n",
    "    precision = tp / denom\n",
    "else:\n",
    "    precision = 0\n",
    "denom = (tp + fn)\n",
    "if denom > 0:\n",
    "    recall = tp / denom\n",
    "else:\n",
    "    recall = 0\n",
    "# Compute F1 score\n",
    "\n",
    "denom = (precision+recall)\n",
    "if denom > 0:\n",
    "    f1 = 2 * ((precision*recall)/denom)\n",
    "else:\n",
    "    f1 = 0\n",
    "# Return all metrics\n",
    "res = {\n",
    "        'tp': tp,\n",
    "        'fp': fp,\n",
    "        'tn': tn,\n",
    "        'fn': fn,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "}\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hrAmOxI41LVB",
   "metadata": {
    "id": "hrAmOxI41LVB"
   },
   "source": [
    "## Alternative Approach 2: Vector Distances between Adjacent images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zlMqzDdlCssH",
   "metadata": {
    "id": "zlMqzDdlCssH"
   },
   "source": [
    "1)Use 5 text queries.\n",
    "\n",
    "2)Select 5 text queries from ImageCIFARTOP5 (which has 68 classes in total):\n",
    "\n",
    "grasshopper,\n",
    "fly,\n",
    "spider,\n",
    "beetle,\n",
    "caterpillar\n",
    "\n",
    "3)Euclidean Distance\n",
    "\n",
    "4) threshold distance to determine boundary\n",
    "- can perform optimisation for point 2 & 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6jCNV7cj156v",
   "metadata": {
    "id": "6jCNV7cj156v"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "import os\n",
    "from PIL import Image\n",
    "import array as arr \n",
    "\n",
    "resultList = []\n",
    "firstCaption = []\n",
    "secondCaption = []\n",
    "thirdCaption = []\n",
    "fourthCaption = []\n",
    "fifthCaption = []\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model, preprocess = clip.load(\"ViT-L/14@336px\", device=device)\n",
    "# list down the text queries in caption list\n",
    "caption = [\"grasshopper\", \"fly\", \"spider\", \"beetle\", \"caterpillar\"]\n",
    "caption.sort()  # sort captions in alphabetical order\n",
    "\n",
    "source_path = '/content/gdrive/MyDrive/Colab Notebooks/data-1/imgs/'\n",
    "dir_contents = os.listdir(source_path) # returns list\n",
    "dir_contents.sort()\n",
    "num_pics = len(dir_contents)   # find number of pictures in directory\n",
    "\n",
    "for i in range(num_pics):\n",
    "#Load and prepare images\n",
    "  print(\"\\nImage Title: \",dir_contents[i]);\n",
    "  image = preprocess(Image.open(source_path + dir_contents[i])).unsqueeze(0).to(device)\n",
    "  caption_inputs = torch.cat([clip.tokenize(f\"a photo of a {c}\") for c in caption]).to(device)\n",
    " \n",
    "  with torch.no_grad():\n",
    "      image_features = model.encode_image(image)\n",
    "      text_features = model.encode_text(caption_inputs)\n",
    "\n",
    "  image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "  text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "  similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "  # save the similarity values and captions for top 5\n",
    "  values, indices = similarity[0].topk(5, sorted = False)\n",
    "\n",
    "  # Create a list of tuples containing the caption and its corresponding score\n",
    "  captions_and_scores = [(caption[idx], values[idx].item()) for idx in indices]\n",
    "  # Sort the list based on the original order of the captions\n",
    "  captions_and_scores.sort(key=lambda x: caption.index(x[0]))\n",
    "\n",
    "  firstCaption.append(captions_and_scores[0][1])\n",
    "  secondCaption.append(captions_and_scores[1][1])\n",
    "  thirdCaption.append(captions_and_scores[2][1])\n",
    "  fourthCaption.append(captions_and_scores[3][1])\n",
    "  fifthCaption.append(captions_and_scores[4][1])\n",
    "\n",
    "  print(\"\\nPredictions:\\n\")\n",
    "  for caption_score in captions_and_scores:\n",
    "      print(f\"{caption_score[0]:>16s}: {caption_score[1]:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FP4bYkDgRr5R",
   "metadata": {
    "id": "FP4bYkDgRr5R"
   },
   "source": [
    "Calculate Euclidean Distance Here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-0_ilaZTdMSW",
   "metadata": {
    "id": "-0_ilaZTdMSW"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "euclidList = []\n",
    "x = len(firstCaption)\n",
    "# initializing points in numpy arrays\n",
    "for i in range (num_pics):\n",
    "  if (firstCaption[i] == firstCaption [x -1]) and   (secondCaption [i] ==secondCaption[x-1]) and (thirdCaption [i] ==thirdCaption[x-1])\\\n",
    "    and (fourthCaption [i] ==fourthCaption[x-1]) and (fifthCaption [i] ==fifthCaption[x-1]):\n",
    "    dist = 0.00\n",
    "\n",
    "  else:\n",
    "    image1 = np.array((firstCaption [i], secondCaption [i], thirdCaption [i], fourthCaption [i],fifthCaption [i]))\n",
    "    image2 = np.array((firstCaption [i+1], secondCaption [i+1], thirdCaption [i+1], fourthCaption [i+1],fifthCaption [i+1]))\n",
    "    dist = np.linalg.norm(image1 - image2)  \n",
    "    # calculating Euclidean distance using linalg.norm()\n",
    "\n",
    "  euclidList.append(dist)\n",
    " \n",
    "# printing Euclidean distance\n",
    "print(f\"Length: {len(euclidList)} \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fPIpKCFgRwUs",
   "metadata": {
    "id": "fPIpKCFgRwUs"
   },
   "source": [
    "Process the input image data into a list with 0, 1 act as the boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Dj7yPZDMNcTC",
   "metadata": {
    "id": "Dj7yPZDMNcTC"
   },
   "outputs": [],
   "source": [
    "boundariesList = []\n",
    "\n",
    "x = len(euclidList)\n",
    "print(f\"\\nNumber of Pics: {num_pics}\")\n",
    "print(f\"Length of List: {x}\" )  \n",
    "for i in range(num_pics):\n",
    "  if euclidList[i] == euclidList[x-1]:    #length count from 1, so need deduct 1\n",
    "    boundariesList.append(0)\n",
    "  elif(abs(euclidList[i]) - (euclidList[i+1]) > 0.40):\n",
    "      boundariesList.append(1)\n",
    "  else:\n",
    "    boundariesList.append(0)\n",
    "\n",
    "for i in range(num_pics):\n",
    "   print(f\"{i+1}. {euclidList[i]} {boundariesList[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "K-tOMONPR4XF",
   "metadata": {
    "id": "K-tOMONPR4XF"
   },
   "source": [
    "Processing the actual boundaries file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RZcH3jPQJrpe",
   "metadata": {
    "id": "RZcH3jPQJrpe"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "boundaries_path_file = \"/content/gdrive/MyDrive/Colab Notebooks/data-1/Boundaries.txt\"\n",
    "boundaries_df = pd.read_csv(boundaries_path_file)\n",
    "bound_strings = boundaries_df.columns.tolist()\n",
    "num_bound = len(bound_strings)\n",
    "bound_int = []\n",
    "\n",
    "#convert string list to int list\n",
    "for i in range(0,len(bound_strings)):\n",
    "    bound_strings[i] = int(bound_strings[i])\n",
    "\n",
    "trueboundariesList = []\n",
    "\n",
    "\n",
    "for j in range(num_pics):                 # num_pics = 273\n",
    "  if j == bound_strings[num_bound -1]:    # -1 cause j start from 0, when 34 meet 34 is last\n",
    "      trueboundariesList.append(0)\n",
    "  elif any(j +1 == y  for y in bound_strings):\n",
    "    trueboundariesList.append(1)\n",
    "  else:\n",
    "     trueboundariesList.append(0)\n",
    "\n",
    "for i in range(num_pics):\n",
    "   print(f\"{i+1}. {trueboundariesList[i]}\")\n",
    "\n",
    "# there are 35 of boundaries detected, which match with the Boundaries.txt for data-1\n",
    "count = len([elem for elem in trueboundariesList if elem == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HpiyfzRDJ85v",
   "metadata": {
    "id": "HpiyfzRDJ85v"
   },
   "outputs": [],
   "source": [
    "# Calculate F-1 \n",
    "\n",
    "# initializations\n",
    "# Compute TP, FP, TN, FN\n",
    "tp = 0; fp = 0; tn = 0; fn = 0;\n",
    "for bi in range(num_pics):\n",
    "    # If actual==1 and pred==1, increment true positives\n",
    "  if (trueboundariesList[bi] == 1) and (boundariesList[bi] == 1):\n",
    "    tp = tp + 1\n",
    "    # If actual==1 and pred==0, increment false negatives\n",
    "  if (trueboundariesList[bi] == 1) and (boundariesList[bi] == 0):\n",
    "    fn = fn + 1\n",
    "    # If actual==0 and pred==1, increment false positives\n",
    "  if (trueboundariesList[bi] == 0) and (boundariesList[bi] == 1):\n",
    "    fp = fp + 1\n",
    "    # If actual==0 and pred==0, increment true negatives\n",
    "  if (trueboundariesList[bi] == 0) and (boundariesList[bi] == 0):\n",
    "    tn = tn + 1\n",
    "\n",
    "# Display tp, fp, tn, fn\n",
    "print('True positives: ', tp)\n",
    "print('False positives: ', fp)\n",
    "print('True negatives: ', tn)\n",
    "print('False negatives: ', fn)\n",
    "\n",
    "# Compute precision and recall\n",
    "denom = (tp + fp)\n",
    "if denom > 0:\n",
    "    precision = tp / denom\n",
    "else:\n",
    "    precision = 0\n",
    "denom = (tp + fn)\n",
    "if denom > 0:\n",
    "    recall = tp / denom\n",
    "else:\n",
    "    recall = 0\n",
    "# Compute F1 score\n",
    "\n",
    "denom = (precision+recall)\n",
    "if denom > 0:\n",
    "    f1 = 2 * ((precision*recall)/denom)\n",
    "else:\n",
    "    f1 = 0\n",
    "# Return all metrics\n",
    "res = {\n",
    "        'tp': tp,\n",
    "        'fp': fp,\n",
    "        'tn': tn,\n",
    "        'fn': fn,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "}\n",
    "\n",
    "print(res)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48M2F3RZR_7p",
   "metadata": {
    "id": "48M2F3RZR_7p"
   },
   "source": [
    "This block of code is to add loop to find the best value for threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3sws2wvRQu0w",
   "metadata": {
    "id": "3sws2wvRQu0w"
   },
   "outputs": [],
   "source": [
    "o = 0.00\n",
    "o_list = []\n",
    "f1_list = []\n",
    "\n",
    "while o <= 1.00:\n",
    "\n",
    "  boundariesList = []\n",
    "\n",
    "  x = len(euclidList)\n",
    "  for i in range(num_pics):\n",
    "    if euclidList[i] == euclidList[x-1]:    #length count from 1, so need deduct 1\n",
    "      boundariesList.append(0)\n",
    "    elif(abs(euclidList[i]) - (euclidList[i+1]) >= o):\n",
    "        boundariesList.append(1)\n",
    "    else:\n",
    "      boundariesList.append(0)\n",
    "\n",
    "\n",
    "  ################################################################\n",
    "    tp = 0; fp = 0; tn = 0; fn = 0;\n",
    "  for bi in range(num_pics):\n",
    "      # If actual==1 and pred==1, increment true positives\n",
    "    if (trueboundariesList[bi] == 1) and (boundariesList[bi] == 1):\n",
    "      tp = tp + 1\n",
    "      # If actual==1 and pred==0, increment false negatives\n",
    "    if (trueboundariesList[bi] == 1) and (boundariesList[bi] == 0):\n",
    "      fn = fn + 1\n",
    "      # If actual==0 and pred==1, increment false positives\n",
    "    if (trueboundariesList[bi] == 0) and (boundariesList[bi] == 1):\n",
    "      fp = fp + 1\n",
    "      # If actual==0 and pred==0, increment true negatives\n",
    "    if (trueboundariesList[bi] == 0) and (boundariesList[bi] == 0):\n",
    "      tn = tn + 1\n",
    "\n",
    "\n",
    "  # Compute precision and recall\n",
    "  denom = (tp + fp)\n",
    "  if denom > 0:\n",
    "      precision = tp / denom\n",
    "  else:\n",
    "      precision = 0\n",
    "  denom = (tp + fn)\n",
    "  if denom > 0:\n",
    "      recall = tp / denom\n",
    "  else:\n",
    "      recall = 0\n",
    "\n",
    "  # Compute F1 score\n",
    "  denom = (precision+recall)\n",
    "  if denom > 0:\n",
    "      f1 = 2 * ((precision*recall)/denom)\n",
    "  else:\n",
    "      f1 = 0\n",
    "  # Return all metrics\n",
    "  res = {\n",
    "          'tp': tp,\n",
    "          'fp': fp,\n",
    "          'tn': tn,\n",
    "          'fn': fn,\n",
    "          'precision': precision,\n",
    "          'recall': recall,\n",
    "          'f1': f1\n",
    "  }\n",
    "  o_list.append(o)\n",
    "  f1_list.append(res['f1'])\n",
    "  o += 0.05\n",
    "\n",
    "print(o_list)\n",
    "print(f1_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dMJNt9__SWad",
   "metadata": {
    "id": "dMJNt9__SWad"
   },
   "source": [
    "Utilising matplotlib to plot out the graph for for relationship between threshold and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oFpiq60tSy35",
   "metadata": {
    "id": "oFpiq60tSy35"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(o_list, f1_list)\n",
    "plt.xlabel(\"Diff_value (O)\")\n",
    "plt.ylabel(\"F1-score\")\n",
    "plt.xlim(0, 1.00)\n",
    "plt.ylim(0, 1.00)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dMJNoR_84Q-",
   "metadata": {
    "id": "3dMJNoR_84Q-"
   },
   "source": [
    "# Experiment 3.2 - Genetic Algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6CEOBlzHSfDL",
   "metadata": {
    "id": "6CEOBlzHSfDL"
   },
   "source": [
    "This experiment will be utilising Genetic Algorithm for selecting best set of queries on top of alternative approach 2. This section is used to generate for both imageCIFARTOP5 and insectDomainClass."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eG3aJF8aM_va",
   "metadata": {
    "id": "eG3aJF8aM_va"
   },
   "source": [
    "Useful resources:\n",
    "  https://towardsdatascience.com/introduction-to-genetic-algorithms-including-example-code-e396e98d8bf3\n",
    "\n",
    "  https://www.kaggle.com/code/aaawnrahman/genetic-algorithm/notebook\n",
    "\n",
    "  https://anderfernandez.com/en/blog/genetic-algorithm-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbPlZmpX88tW",
   "metadata": {
    "id": "dbPlZmpX88tW"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "import os\n",
    "from PIL import Image\n",
    "import array as arr \n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# pass in the captions folder\n",
    "with open('/content/gdrive/MyDrive/Colab Notebooks/insectDomainClass.txt') as f:\n",
    "    image_descriptions = [line.rstrip() for line in f]\n",
    "\n",
    "model, preprocess = clip.load(\"ViT-L/14@336px\", device=device)\n",
    "source_path = '/content/gdrive/MyDrive/Colab Notebooks/data-1/imgs/'\n",
    "dir_contents = os.listdir(source_path) \n",
    "dir_contents.sort()\n",
    "num_pics = len(dir_contents)   \n",
    "\n",
    "# Here convert list into dictionary with 'int' as key\n",
    "list1 = list(range(1,len(image_descriptions)+1))\n",
    "list2 = []\n",
    "\n",
    "# here append queries into list\n",
    "for c in image_descriptions:\n",
    "  list2.append(c)\n",
    "\n",
    "class_dictionary = dict(zip(list1, list2))\n",
    "print(class_dictionary)\n",
    "\n",
    "# here can access the value from key\n",
    "#x = class_dictionary.get()\n",
    "#y = class_dictionary.get()\n",
    "#print(x)\n",
    "#print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3XC7vaM2S9M3",
   "metadata": {
    "id": "3XC7vaM2S9M3"
   },
   "source": [
    "Process the actual boundaries file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fqnap0UmHIHd",
   "metadata": {
    "id": "fqnap0UmHIHd"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "boundaries_path_file = \"/content/gdrive/MyDrive/Colab Notebooks/data-1/Boundaries.txt\"\n",
    "boundaries_df = pd.read_csv(boundaries_path_file)\n",
    "bound_strings = boundaries_df.columns.tolist()\n",
    "num_bound = len(bound_strings)\n",
    "bound_int = []\n",
    "\n",
    "#convert string list to int list\n",
    "for i in range(0,len(bound_strings)):\n",
    "    bound_strings[i] = int(bound_strings[i])\n",
    "\n",
    "trueboundariesList = []\n",
    "\n",
    "\n",
    "for j in range(num_pics):                 # num_pics = 273\n",
    "  if j == bound_strings[num_bound -1]:    # -1 cause j start from 0, when 34 meet 34 is last\n",
    "      trueboundariesList.append(0)\n",
    "  elif any(j +1 == y  for y in bound_strings):\n",
    "    trueboundariesList.append(1)\n",
    "  else:\n",
    "     trueboundariesList.append(0)\n",
    "\n",
    "for i in range(num_pics):\n",
    "   print(f\"{i+1}. {trueboundariesList[i]}\")\n",
    "\n",
    "# there are 35 of boundaries detected, which match with the Boundaries.txt for data-1\n",
    "count = len([elem for elem in trueboundariesList if elem == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wSPY-158TD0G",
   "metadata": {
    "id": "wSPY-158TD0G"
   },
   "source": [
    "Perform optimisation to seach optimal sets of text queries using genetic algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MYju03cu_Q1o",
   "metadata": {
    "id": "MYju03cu_Q1o"
   },
   "outputs": [],
   "source": [
    "# Generate initial chromosomes\n",
    "from operator import itemgetter\n",
    "\n",
    "def generate_initial_population():\n",
    "    initial_population = []\n",
    "    for x in range(6):\n",
    "        new_chromosome = []\n",
    "        for y in range(5):\n",
    "            new_chromosome.append(random.randint(1,len(image_descriptions))) \n",
    "        initial_population.append(new_chromosome)\n",
    "    return initial_population\n",
    "\n",
    "# Evaluate fitness of chromosome\n",
    "def evaluate_chromosome(chromosome):\n",
    "    queriesList = []\n",
    "    queriesList.append(class_dictionary.get(chromosome[0]))\n",
    "    queriesList.append(class_dictionary.get(chromosome[1]))\n",
    "    queriesList.append(class_dictionary.get(chromosome[2]))\n",
    "    queriesList.append(class_dictionary.get(chromosome[3]))\n",
    "    queriesList.append(class_dictionary.get(chromosome[4]))\n",
    "    queriesList.sort()\n",
    "\n",
    "    firstCaption = []\n",
    "    secondCaption = []\n",
    "    thirdCaption = []\n",
    "    fourthCaption = []\n",
    "    fifthCaption = []\n",
    "\n",
    "    dir_contents = os.listdir(source_path) # returns list\n",
    "    dir_contents.sort()\n",
    "    num_pics = len(dir_contents)   # find number of pictures in directory\n",
    "\n",
    "    for i in range(num_pics):\n",
    "    #Load and prepare images\n",
    "      image = preprocess(Image.open(source_path + dir_contents[i])).unsqueeze(0).to(device)\n",
    "      caption_inputs = torch.cat([clip.tokenize(f\"a photo of a {c}\") for c in queriesList]).to(device)\n",
    "\n",
    "      with torch.no_grad():\n",
    "          image_features = model.encode_image(image)\n",
    "          text_features = model.encode_text(caption_inputs)\n",
    "\n",
    "      image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "      text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "      similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "      values, indices = similarity[0].topk(5, sorted = False)\n",
    "\n",
    "      # Create a list of tuples containing the caption and its corresponding score\n",
    "      captions_and_scores = [(queriesList[idx], values[idx].item()) for idx in indices]\n",
    "      # Sort the list based on the original order of the captions\n",
    "      captions_and_scores.sort(key=lambda x: queriesList.index(x[0]))\n",
    "\n",
    "      firstCaption.append(captions_and_scores[0][1])\n",
    "      secondCaption.append(captions_and_scores[1][1])\n",
    "      thirdCaption.append(captions_and_scores[2][1])\n",
    "      fourthCaption.append(captions_and_scores[3][1])\n",
    "      fifthCaption.append(captions_and_scores[4][1])\n",
    "\n",
    "    euclidList = []\n",
    "    x = len(firstCaption)\n",
    "    # initializing points in numpy arrays\n",
    "    for i in range (num_pics):\n",
    "      if (firstCaption[i] == firstCaption [x -1]) and   (secondCaption [i] ==secondCaption[x-1]) and (thirdCaption [i] ==thirdCaption[x-1]) and (fourthCaption [i] ==fourthCaption[x-1]) and (fifthCaption [i] ==fifthCaption[x-1]):\n",
    "        dist = 0.00\n",
    "      else:\n",
    "        image1 = np.array((firstCaption [i], secondCaption [i], thirdCaption [i], fourthCaption [i],fifthCaption [i]))\n",
    "        image2 = np.array((firstCaption [i+1], secondCaption [i+1], thirdCaption [i+1], fourthCaption [i+1],fifthCaption [i+1]))\n",
    "        dist = np.linalg.norm(image1 - image2)\n",
    "\n",
    "      euclidList.append(dist)\n",
    "\n",
    "    boundariesList = []\n",
    "\n",
    "    x = len(euclidList)\n",
    "    for i in range(num_pics):\n",
    "      if euclidList[i] == euclidList[x-1]:    #length count from 1, so need deduct 1\n",
    "        boundariesList.append(0)\n",
    "      elif(abs(euclidList[i]) - (euclidList[i+1]) > 0.40):\n",
    "        boundariesList.append(1)\n",
    "      else:\n",
    "        boundariesList.append(0)\n",
    "\n",
    "    tp = 0; fp = 0; tn = 0; fn = 0;\n",
    "    for bi in range(num_pics):\n",
    "        # If actual==1 and pred==1, increment true positives\n",
    "      if (trueboundariesList[bi] == 1) and (boundariesList[bi] == 1):\n",
    "        tp = tp + 1\n",
    "        # If actual==1 and pred==0, increment false negatives\n",
    "      if (trueboundariesList[bi] == 1) and (boundariesList[bi] == 0):\n",
    "        fn = fn + 1\n",
    "        # If actual==0 and pred==1, increment false positives\n",
    "      if (trueboundariesList[bi] == 0) and (boundariesList[bi] == 1):\n",
    "        fp = fp + 1\n",
    "        # If actual==0 and pred==0, increment true negatives\n",
    "      if (trueboundariesList[bi] == 0) and (boundariesList[bi] == 0):\n",
    "        tn = tn + 1\n",
    "\n",
    "    # Compute precision and recall\n",
    "    denom = (tp + fp)\n",
    "    if denom > 0:\n",
    "        precision = tp / denom\n",
    "    else:\n",
    "        precision = 0\n",
    "    denom = (tp + fn)\n",
    "    if denom > 0:\n",
    "        recall = tp / denom\n",
    "    else:\n",
    "        recall = 0\n",
    "    # Compute F1 score\n",
    "\n",
    "    denom = (precision+recall)\n",
    "    if denom > 0:\n",
    "        f1 = 2 * ((precision*recall)/denom)\n",
    "    else:\n",
    "        f1 = 0\n",
    "    # Return all metrics\n",
    "    res = {\n",
    "            'tp': tp,\n",
    "            'fp': fp,\n",
    "            'tn': tn,\n",
    "            'fn': fn,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1\n",
    "    }\n",
    "    fitness = res['f1']\n",
    "    return fitness\n",
    "\n",
    "# Evaluate fitness of population\n",
    "def evaluate_population(population):\n",
    "    evaluated_population = []\n",
    "    for chromosome in population:\n",
    "        fitness = evaluate_chromosome(chromosome)\n",
    "        evaluated_population.append((chromosome, fitness))\n",
    "    return evaluated_population\n",
    "\n",
    "# Save top 3 fittest chromosome\n",
    "def evaluate_fittest(old_list, new_list):\n",
    "    # Adds all data to same list\n",
    "    improved_list = list(old_list)\n",
    "    improved_list.extend(x for x in new_list if x not in improved_list)\n",
    "    # Sort list\n",
    "    improved_list.sort(key=lambda x: x[1], reverse=True)\n",
    "    # Return top 3 chromosomes only\n",
    "    return improved_list[:3]\n",
    "\n",
    "# Tournament selection for parents\n",
    "def tournament_selection(evaluated_population):\n",
    "    new_parents = []\n",
    "    for x in range(6):\n",
    "      # from the population generated last round, randomly select 1 to be parents from 3\n",
    "        random_sample = random.sample(evaluated_population, 3)\n",
    "        new_parent = max(random_sample, key=itemgetter(1))[0]     # 1 means second variables, so is saying fitness here. [0] is return highest fitness\n",
    "        new_parents.append(new_parent)\n",
    "    return new_parents\n",
    "\n",
    "# Chromosome crossover\n",
    "def crossover(first_parent, second_parent):\n",
    "    # No crossover occurs\n",
    "    if random.random() > CROSSOVER_RATE:\n",
    "        chromosomes = [first_parent.copy(), second_parent.copy()]\n",
    "    else:\n",
    "        # Single crossover\n",
    "        chromosomes = single_crossover(first_parent, second_parent)\n",
    "    return chromosomes\n",
    "\n",
    "# Single-point crossover\n",
    "def single_crossover(first_parent, second_parent):\n",
    "    # Get crossover point\n",
    "    crossover_point = random.randint(1, 3)\n",
    "    # Perform crossover\n",
    "    first_chromosome = first_parent[:crossover_point] + second_parent[crossover_point:]\n",
    "    second_chromosome = second_parent[:crossover_point] + first_parent[crossover_point:]\n",
    "    return [first_chromosome, second_chromosome]\n",
    "\n",
    "# Mutate chromosome\n",
    "def mutate_chromosome(chromosome):\n",
    "    for x in range(4):\n",
    "        if random.random() < MUTATION_RATE:\n",
    "            chromosome[x] = random.randint(1,len(image_descriptions))\n",
    "\n",
    "# Genetic algorithm\n",
    "def genetic_algorithm():\n",
    "    # Generate initial population\n",
    "    population = generate_initial_population()\n",
    "    # Top 3 fittest chromosomes\n",
    "    fittest_chromosomes = []\n",
    "    # Run for 10 generations\n",
    "    for generation in range(10):\n",
    "        # Evaluate population\n",
    "        evaluated_population = evaluate_population(population)\n",
    "        # Reevaluate fittest chromosome\n",
    "        fittest_chromosomes = evaluate_fittest(fittest_chromosomes, evaluated_population)\n",
    "        print([x[1] for x in fittest_chromosomes])\n",
    "        # Attain new parents\n",
    "        new_parents = tournament_selection(evaluated_population)\n",
    "        # New population\n",
    "        new_population = []\n",
    "        # Generate new population\n",
    "        for x in range(0, 6, 2):\n",
    "            # Get new parents\n",
    "            first_parent, second_parent = new_parents[x], new_parents[x + 1]\n",
    "            # Mutate new chromosomes\n",
    "            for chromosome in crossover(first_parent, second_parent):\n",
    "                # Mutate chromosome\n",
    "                mutate_chromosome(chromosome)\n",
    "                # Get mutated chromosome\n",
    "                new_population.append(chromosome)\n",
    "        # Replace population\n",
    "        population = new_population\n",
    "    # Return top 3 fittest chromosomes\n",
    "    return fittest_chromosomes\n",
    "\n",
    "CROSSOVER_RATE = 0.80\n",
    "MUTATION_RATE = 0.20 \n",
    "\n",
    "genetic_algorithm()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efSMR0M5ktLz",
   "metadata": {
    "id": "efSMR0M5ktLz"
   },
   "outputs": [],
   "source": [
    "x = class_dictionary.get(44)\n",
    "y = class_dictionary.get(23)\n",
    "z = class_dictionary.get(58)\n",
    "a = class_dictionary.get(24)\n",
    "b = class_dictionary.get(12)\n",
    "print(f\"{x},{y},{z},{a},{b}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-Ug1WwBuU4rd",
   "metadata": {
    "id": "-Ug1WwBuU4rd"
   },
   "source": [
    "# Experiment 3.3 - Number of Text Queries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QSj3B3NDVhzV",
   "metadata": {
    "id": "QSj3B3NDVhzV"
   },
   "source": [
    "This section is experimenting with the impact of different numbers of text queries. Focus here is 10 and 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "M5QB7BGsU_w5",
   "metadata": {
    "id": "M5QB7BGsU_w5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "import os\n",
    "from PIL import Image\n",
    "import array as arr \n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# some initial set up\n",
    "with open('/content/gdrive/MyDrive/Colab Notebooks/insectDomainClass.txt') as f:\n",
    "    image_descriptions = [line.rstrip() for line in f]\n",
    "\n",
    "model, preprocess = clip.load(\"ViT-L/14@336px\", device=device)\n",
    "source_path = '/content/gdrive/MyDrive/Colab Notebooks/data-1/imgs/'\n",
    "dir_contents = os.listdir(source_path) \n",
    "dir_contents.sort()\n",
    "num_pics = len(dir_contents)   \n",
    "\n",
    "# Here convert list into dictionary with 'int' as key\n",
    "list1 = list(range(1,len(image_descriptions)+1))\n",
    "list2 = []\n",
    "\n",
    "# here append queries into list\n",
    "for c in image_descriptions:\n",
    "  list2.append(c)\n",
    "\n",
    "class_dictionary = dict(zip(list1, list2))\n",
    "print(class_dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qi6P3sNlVS_b",
   "metadata": {
    "id": "qi6P3sNlVS_b"
   },
   "outputs": [],
   "source": [
    "# Processing the actual boundaries file\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "boundaries_path_file = \"/content/gdrive/MyDrive/Colab Notebooks/data-1/Boundaries.txt\"\n",
    "boundaries_df = pd.read_csv(boundaries_path_file)\n",
    "bound_strings = boundaries_df.columns.tolist()\n",
    "num_bound = len(bound_strings)\n",
    "bound_int = []\n",
    "\n",
    "#convert string list to int list\n",
    "for i in range(0,len(bound_strings)):\n",
    "    bound_strings[i] = int(bound_strings[i])\n",
    "\n",
    "trueboundariesList = []\n",
    "\n",
    "\n",
    "for j in range(num_pics):                 # num_pics = 273\n",
    "  if j == bound_strings[num_bound -1]:    # -1 cause j start from 0, when 34 meet 34 is last\n",
    "      trueboundariesList.append(0)\n",
    "  elif any(j +1 == y  for y in bound_strings):\n",
    "    trueboundariesList.append(1)\n",
    "  else:\n",
    "     trueboundariesList.append(0)\n",
    "\n",
    "for i in range(num_pics):\n",
    "   print(f\"{i+1}. {trueboundariesList[i]}\")\n",
    "\n",
    "# there are 35 of boundaries detected, which match with the Boundaries.txt for data-1\n",
    "count = len([elem for elem in trueboundariesList if elem == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Wcr8VW1FU4U3",
   "metadata": {
    "id": "Wcr8VW1FU4U3"
   },
   "source": [
    "The genetic algorithm below is used to find the optimal text queries for 10 and 15. I had commented out 10 text queries related code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IHkXA_7eVb1X",
   "metadata": {
    "id": "IHkXA_7eVb1X"
   },
   "outputs": [],
   "source": [
    "# Generate initial chromosomes\n",
    "from operator import itemgetter\n",
    "\n",
    "def generate_initial_population():\n",
    "    initial_population = []\n",
    "    for x in range(6):\n",
    "        new_chromosome = []\n",
    "        #for y in range(10):\n",
    "        for y in range(15):\n",
    "            new_chromosome.append(random.randint(1,len(image_descriptions))) \n",
    "        initial_population.append(new_chromosome)\n",
    "    return initial_population\n",
    "\n",
    "# Evaluate fitness of chromosome\n",
    "def evaluate_chromosome(chromosome):\n",
    "    queriesList = []\n",
    "    queriesList.append(class_dictionary.get(chromosome[0]))\n",
    "    queriesList.append(class_dictionary.get(chromosome[1]))\n",
    "    queriesList.append(class_dictionary.get(chromosome[2]))\n",
    "    queriesList.append(class_dictionary.get(chromosome[3]))\n",
    "    queriesList.append(class_dictionary.get(chromosome[4]))\n",
    "    queriesList.append(class_dictionary.get(chromosome[5]))\n",
    "    queriesList.append(class_dictionary.get(chromosome[6]))\n",
    "    queriesList.append(class_dictionary.get(chromosome[7]))\n",
    "    queriesList.append(class_dictionary.get(chromosome[8]))\n",
    "    queriesList.append(class_dictionary.get(chromosome[9]))\n",
    "\n",
    "    queriesList.append(class_dictionary.get(chromosome[10]))\n",
    "    queriesList.append(class_dictionary.get(chromosome[11]))\n",
    "    queriesList.append(class_dictionary.get(chromosome[12]))\n",
    "    queriesList.append(class_dictionary.get(chromosome[13]))\n",
    "    queriesList.append(class_dictionary.get(chromosome[14]))\n",
    "\n",
    "    queriesList.sort()\n",
    "    \n",
    "    firstCaption = []\n",
    "    secondCaption = []\n",
    "    thirdCaption = []\n",
    "    fourthCaption = []\n",
    "    fifthCaption = []\n",
    "    sixthCaption = []\n",
    "    seventhCaption = []\n",
    "    eighthCaption = []\n",
    "    ninthCaption = []\n",
    "    tenthCaption = []\n",
    "\n",
    "    elevenCaption = []\n",
    "    twelveCaption = []\n",
    "    thirteenCaption = []\n",
    "    fourteenCaption = []\n",
    "    fifteenCaption = []\n",
    "\n",
    "    dir_contents = os.listdir(source_path) # returns list\n",
    "    dir_contents.sort()\n",
    "    num_pics = len(dir_contents)   # find number of pictures in directory\n",
    "\n",
    "    for i in range(num_pics):\n",
    "    #Load and prepare images\n",
    "      image = preprocess(Image.open(source_path + dir_contents[i])).unsqueeze(0).to(device)\n",
    "      caption_inputs = torch.cat([clip.tokenize(f\"a photo of a {c}\") for c in queriesList]).to(device)\n",
    "\n",
    "      with torch.no_grad():\n",
    "          image_features = model.encode_image(image)\n",
    "          text_features = model.encode_text(caption_inputs)\n",
    "\n",
    "      image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "      text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "      similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "      #values, indices = similarity[0].topk(10, sorted = False)\n",
    "      values, indices = similarity[0].topk(15, sorted = False)\n",
    "\n",
    "      # Create a list of tuples containing the caption and its corresponding score\n",
    "      captions_and_scores = [(queriesList[idx], values[idx].item()) for idx in indices]\n",
    "      # Sort the list based on the original order of the captions\n",
    "      captions_and_scores.sort(key=lambda x: queriesList.index(x[0]))\n",
    "\n",
    "      firstCaption.append(captions_and_scores[0][1])\n",
    "      secondCaption.append(captions_and_scores[1][1])\n",
    "      thirdCaption.append(captions_and_scores[2][1])\n",
    "      fourthCaption.append(captions_and_scores[3][1])\n",
    "      fifthCaption.append(captions_and_scores[4][1])\n",
    "      sixthCaption.append(captions_and_scores[5][1])\n",
    "      seventhCaption.append(captions_and_scores[6][1])\n",
    "      eighthCaption.append(captions_and_scores[7][1])\n",
    "      ninthCaption.append(captions_and_scores[8][1])\n",
    "      tenthCaption.append(captions_and_scores[9][1])\n",
    "\n",
    "      elevenCaption.append(captions_and_scores[10][1])\n",
    "      twelveCaption.append(captions_and_scores[11][1])\n",
    "      thirteenCaption.append(captions_and_scores[12][1])\n",
    "      fourteenCaption.append(captions_and_scores[13][1])\n",
    "      fifteenCaption.append(captions_and_scores[14][1])\n",
    "\n",
    "    euclidList = []\n",
    "    x = len(firstCaption)\n",
    "    # initializing points in numpy arrays\n",
    "    for i in range (num_pics):\n",
    "      if (firstCaption[i] == firstCaption [x -1]) and   (secondCaption [i] ==secondCaption[x-1]) and (thirdCaption [i] ==thirdCaption[x-1]) and \\\n",
    "      (fourthCaption [i] ==fourthCaption[x-1]) and (fifthCaption [i] ==fifthCaption[x-1]) and (sixthCaption [i] == sixthCaption[x-1])\\\n",
    "      and (seventhCaption [i] ==seventhCaption[x-1])and (eighthCaption [i] ==eighthCaption[x-1])and (ninthCaption [i] ==ninthCaption[x-1])\\\n",
    "      and (tenthCaption [i] ==tenthCaption[x-1]) and (elevenCaption[i] == elevenCaption [x -1]) and   (twelveCaption [i] ==twelveCaption[x-1]) \\\n",
    "      and (thirteenCaption [i] ==thirteenCaption[x-1]) and (fourteenCaption [i] ==fourteenCaption[x-1]) and (fifteenCaption [i] ==fifteenCaption[x-1]):\n",
    "        dist = 0.00\n",
    "      else:\n",
    "        image1 = np.array((firstCaption [i], secondCaption [i], thirdCaption [i], fourthCaption [i],fifthCaption [i],sixthCaption [i], seventhCaption [i], eighthCaption [i], ninthCaption [i],tenthCaption [i],\\\n",
    "                           elevenCaption [i], twelveCaption [i], thirteenCaption [i], fourteenCaption [i],fifteenCaption [i]))\n",
    "        image2 = np.array((firstCaption [i+1], secondCaption [i+1], thirdCaption [i+1], fourthCaption [i+1],fifthCaption [i+1],sixthCaption [i+1], seventhCaption [i+1], eighthCaption [i+1], ninthCaption [i+1],tenthCaption [i+1],\\\n",
    "                           elevenCaption [i+1], twelveCaption [i+1], thirteenCaption [i+1], fourteenCaption [i+1],fifteenCaption [i+1]))\n",
    "        dist = np.linalg.norm(image1 - image2)\n",
    "\n",
    "      euclidList.append(dist)\n",
    "\n",
    "    boundariesList = []\n",
    "\n",
    "    x = len(euclidList)\n",
    "    for i in range(num_pics):\n",
    "      if euclidList[i] == euclidList[x-1]:    #length count from 1, so need deduct 1\n",
    "        boundariesList.append(0)\n",
    "      elif(abs(euclidList[i]) - (euclidList[i+1]) > 0.40):\n",
    "        boundariesList.append(1)\n",
    "      else:\n",
    "        boundariesList.append(0)\n",
    "\n",
    "    tp = 0; fp = 0; tn = 0; fn = 0;\n",
    "    for bi in range(num_pics):\n",
    "        # If actual==1 and pred==1, increment true positives\n",
    "      if (trueboundariesList[bi] == 1) and (boundariesList[bi] == 1):\n",
    "        tp = tp + 1\n",
    "        # If actual==1 and pred==0, increment false negatives\n",
    "      if (trueboundariesList[bi] == 1) and (boundariesList[bi] == 0):\n",
    "        fn = fn + 1\n",
    "        # If actual==0 and pred==1, increment false positives\n",
    "      if (trueboundariesList[bi] == 0) and (boundariesList[bi] == 1):\n",
    "        fp = fp + 1\n",
    "        # If actual==0 and pred==0, increment true negatives\n",
    "      if (trueboundariesList[bi] == 0) and (boundariesList[bi] == 0):\n",
    "        tn = tn + 1\n",
    "\n",
    "    # Compute precision and recall\n",
    "    denom = (tp + fp)\n",
    "    if denom > 0:\n",
    "        precision = tp / denom\n",
    "    else:\n",
    "        precision = 0\n",
    "    denom = (tp + fn)\n",
    "    if denom > 0:\n",
    "        recall = tp / denom\n",
    "    else:\n",
    "        recall = 0\n",
    "    # Compute F1 score\n",
    "\n",
    "    denom = (precision+recall)\n",
    "    if denom > 0:\n",
    "        f1 = 2 * ((precision*recall)/denom)\n",
    "    else:\n",
    "        f1 = 0\n",
    "    # Return all metrics\n",
    "    res = {\n",
    "            'tp': tp,\n",
    "            'fp': fp,\n",
    "            'tn': tn,\n",
    "            'fn': fn,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1\n",
    "    }\n",
    "    fitness = res['f1']\n",
    "    return fitness\n",
    "\n",
    "# Evaluate fitness of population\n",
    "def evaluate_population(population):\n",
    "    evaluated_population = []\n",
    "    for chromosome in population:\n",
    "        fitness = evaluate_chromosome(chromosome)\n",
    "        evaluated_population.append((chromosome, fitness))\n",
    "    return evaluated_population\n",
    "\n",
    "# Save top 3 fittest chromosome\n",
    "def evaluate_fittest(old_list, new_list):\n",
    "    # Adds all data to same list\n",
    "    improved_list = list(old_list)\n",
    "    improved_list.extend(x for x in new_list if x not in improved_list)\n",
    "    # Sort list\n",
    "    improved_list.sort(key=lambda x: x[1], reverse=True)\n",
    "    # Return top 3 chromosomes only\n",
    "    return improved_list[:3]\n",
    "\n",
    "# Tournament selection for parents\n",
    "def tournament_selection(evaluated_population):\n",
    "    new_parents = []\n",
    "    for x in range(6):\n",
    "        random_sample = random.sample(evaluated_population, 3)    # from the population generated last round, randomly select 1 to be parents\n",
    "        new_parent = max(random_sample, key=itemgetter(1))[0]     # 1 means second variables, so is saying fitness here. [0] is return highest 1\n",
    "        new_parents.append(new_parent)\n",
    "    return new_parents\n",
    "\n",
    "# Single-point crossover\n",
    "def single_crossover(first_parent, second_parent):\n",
    "    # Get crossover point\n",
    "    #crossover_point = random.randint(1, 8)\n",
    "    crossover_point = random.randint(1, 13)\n",
    "    # Perform crossover\n",
    "    first_chromosome = first_parent[:crossover_point] + second_parent[crossover_point:]\n",
    "    second_chromosome = second_parent[:crossover_point] + first_parent[crossover_point:]\n",
    "    return [first_chromosome, second_chromosome]\n",
    "\n",
    "\n",
    "# Chromosome crossover\n",
    "def crossover(first_parent, second_parent):\n",
    "    # No crossover occurs\n",
    "    if random.random() > CROSSOVER_RATE:\n",
    "        chromosomes = [first_parent.copy(), second_parent.copy()]\n",
    "    else:\n",
    "        # Single crossover\n",
    "        chromosomes = single_crossover(first_parent, second_parent)\n",
    "    return chromosomes\n",
    "\n",
    "# Mutate chromosome\n",
    "def mutate_chromosome(chromosome):\n",
    "    #for x in range(9):\n",
    "    for x in range(14):\n",
    "        if random.random() < MUTATION_RATE:\n",
    "            chromosome[x] = random.randint(1,len(image_descriptions))\n",
    "\n",
    "# Genetic algorithm\n",
    "def genetic_algorithm():\n",
    "    # Generate initial population\n",
    "    population = generate_initial_population()\n",
    "    # Top 3 fittest chromosomes\n",
    "    fittest_chromosomes = []\n",
    "    # Run for 10 generations\n",
    "    for generation in range(10):\n",
    "        # Evaluate population\n",
    "        evaluated_population = evaluate_population(population)\n",
    "        # Reevaluate fittest chromosome\n",
    "        fittest_chromosomes = evaluate_fittest(fittest_chromosomes, evaluated_population)\n",
    "        print([x[1] for x in fittest_chromosomes])\n",
    "        # Get new parents\n",
    "        new_parents = tournament_selection(evaluated_population)\n",
    "        # New population\n",
    "        new_population = []\n",
    "        # Generate new population\n",
    "        for x in range(0, 6, 2):\n",
    "            # Attain new parents\n",
    "            first_parent, second_parent = new_parents[x], new_parents[x + 1]\n",
    "            # Mutate new chromosomes\n",
    "            for chromosome in crossover(first_parent, second_parent):\n",
    "                # Mutate chromosome\n",
    "                mutate_chromosome(chromosome)\n",
    "                # Get mutated chromosome\n",
    "                new_population.append(chromosome)\n",
    "        # Replace population\n",
    "        population = new_population\n",
    "    # Return top 3 fittest chromosomes\n",
    "    return fittest_chromosomes\n",
    "\n",
    "CROSSOVER_RATE = 0.80\n",
    "MUTATION_RATE = 0.067   # for 15 text queries\n",
    "#MUTATION_RATE = 0.10   # for 10 text queries\n",
    "\n",
    "genetic_algorithm()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PrEBnfnPbjRn",
   "metadata": {
    "id": "PrEBnfnPbjRn"
   },
   "outputs": [],
   "source": [
    "a = class_dictionary.get(1)\n",
    "b = class_dictionary.get(25)\n",
    "c = class_dictionary.get(2)\n",
    "d = class_dictionary.get(53)\n",
    "e = class_dictionary.get(52)\n",
    "f = class_dictionary.get(37)\n",
    "g = class_dictionary.get(15)\n",
    "h = class_dictionary.get(44)\n",
    "i = class_dictionary.get(3)\n",
    "j = class_dictionary.get(7)\n",
    "\n",
    "k = class_dictionary.get(53)\n",
    "l = class_dictionary.get(31)\n",
    "m = class_dictionary.get(32)\n",
    "n = class_dictionary.get(26)\n",
    "o = class_dictionary.get(22)\n",
    "\n",
    "#print(f\"{a},{b},{c},{d},{e},{f},{g},{h},{i},{j}\")\n",
    "print(f\"{a},{b},{c},{d},{e},{f},{g},{h},{i},{j},{k},{l},{m},{n},{o}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FJyN_p2Ga3BS",
   "metadata": {
    "id": "FJyN_p2Ga3BS"
   },
   "source": [
    "This section is to explore the interpretability of captions, test and perform threshold optimisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Pg3kR6SNchO8",
   "metadata": {
    "id": "Pg3kR6SNchO8"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "import os\n",
    "from PIL import Image\n",
    "import array as arr \n",
    "\n",
    "resultList = []\n",
    "firstCaption = []\n",
    "secondCaption = []\n",
    "thirdCaption = []\n",
    "fourthCaption = []\n",
    "fifthCaption = []\n",
    "sixthCaption = []\n",
    "seventhCaption = []\n",
    "eighthCaption = []\n",
    "ninthCaption = []\n",
    "tenthCaption = []\n",
    "\n",
    "elevenCaption = []\n",
    "twelveCaption = []\n",
    "thirteenCaption = []\n",
    "fourteenCaption = []\n",
    "fifteenCaption = []\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model, preprocess = clip.load(\"ViT-L/14@336px\", device=device)\n",
    "# input the text queries in caption list\n",
    "caption = [\"scorpion\",\"angel insects\",\"heelwalker\",\"lacewing\",\"booklice\",\"flea\"\n",
    ",\"stonefly\",\"thrips\",\"true bug\",\"ice crawler\",\"harvestmen\",\"webspinner\",\"earwig\",\"katydid\",\"cricket\"]\n",
    "caption.sort()  # sort captions in alphabetical order\n",
    "\n",
    "source_path = '/content/gdrive/MyDrive/Colab Notebooks/data-1/imgs/'\n",
    "dir_contents = os.listdir(source_path) # returns list\n",
    "dir_contents.sort()\n",
    "num_pics = len(dir_contents)   # find number of pictures in directory\n",
    "\n",
    "for i in range(num_pics):\n",
    "#Load and prepare images\n",
    "  print(\"\\nImage Title: \",dir_contents[i]);\n",
    "  image = preprocess(Image.open(source_path + dir_contents[i])).unsqueeze(0).to(device)\n",
    "  caption_inputs = torch.cat([clip.tokenize(f\"a photo of a {c}\") for c in caption]).to(device)\n",
    " \n",
    "  with torch.no_grad():\n",
    "      image_features = model.encode_image(image)\n",
    "      text_features = model.encode_text(caption_inputs)\n",
    "\n",
    "  image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "  text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "  similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "  #values, indices = similarity[0].topk(10, sorted = False)\n",
    "  values, indices = similarity[0].topk(15, sorted = False)\n",
    "\n",
    "  # Create a list of tuples containing the caption and its corresponding score\n",
    "  captions_and_scores = [(caption[idx], values[idx].item()) for idx in indices]\n",
    "  # Sort the list based on the original order of the captions\n",
    "  captions_and_scores.sort(key=lambda x: caption.index(x[0]))\n",
    "\n",
    "  firstCaption.append(captions_and_scores[0][1])\n",
    "  secondCaption.append(captions_and_scores[1][1])\n",
    "  thirdCaption.append(captions_and_scores[2][1])\n",
    "  fourthCaption.append(captions_and_scores[3][1])\n",
    "  fifthCaption.append(captions_and_scores[4][1])\n",
    "  sixthCaption.append(captions_and_scores[5][1])\n",
    "  seventhCaption.append(captions_and_scores[6][1])\n",
    "  eighthCaption.append(captions_and_scores[7][1])\n",
    "  ninthCaption.append(captions_and_scores[8][1])\n",
    "  tenthCaption.append(captions_and_scores[9][1])\n",
    "\n",
    "  elevenCaption.append(captions_and_scores[10][1])\n",
    "  twelveCaption.append(captions_and_scores[11][1])\n",
    "  thirteenCaption.append(captions_and_scores[12][1])\n",
    "  fourteenCaption.append(captions_and_scores[13][1])\n",
    "  fifteenCaption.append(captions_and_scores[14][1])\n",
    "\n",
    "  print(\"\\nPredictions:\\n\")\n",
    "  for caption_score in captions_and_scores:\n",
    "      print(f\"{caption_score[0]:>16s}: {caption_score[1]:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xkcPvQG5dGmo",
   "metadata": {
    "id": "xkcPvQG5dGmo"
   },
   "outputs": [],
   "source": [
    "# Calculate Euclidean Distance Here \n",
    "import numpy as np\n",
    "\n",
    "euclidList = []\n",
    "x = len(firstCaption)\n",
    "# initializing points in numpy arrays\n",
    "for i in range (num_pics):\n",
    "  if (firstCaption[i] == firstCaption [x -1]) and   (secondCaption [i] ==secondCaption[x-1]) and (thirdCaption [i] ==thirdCaption[x-1]) and \\\n",
    "    (fourthCaption [i] ==fourthCaption[x-1]) and (fifthCaption [i] ==fifthCaption[x-1]) and (sixthCaption [i] == sixthCaption[x-1])\\\n",
    "    and (seventhCaption [i] ==seventhCaption[x-1])and (eighthCaption [i] ==eighthCaption[x-1])and (ninthCaption [i] ==ninthCaption[x-1])\\\n",
    "    and (tenthCaption [i] ==tenthCaption[x-1]) and (elevenCaption[i] == elevenCaption [x -1]) and   (twelveCaption [i] ==twelveCaption[x-1]) \\\n",
    "    and (thirteenCaption [i] ==thirteenCaption[x-1]) and (fourteenCaption [i] ==fourteenCaption[x-1]) and (fifteenCaption [i] ==fifteenCaption[x-1]):\n",
    "    dist = 0.00\n",
    "\n",
    "  else:\n",
    "    image1 = np.array((firstCaption [i], secondCaption [i], thirdCaption [i], fourthCaption [i],fifthCaption [i],sixthCaption [i], seventhCaption [i], eighthCaption [i], ninthCaption [i],tenthCaption [i],\\\n",
    "                       elevenCaption [i], twelveCaption [i], thirteenCaption [i], fourteenCaption [i],fifteenCaption [i]))\n",
    "    image2 = np.array((firstCaption [i+1], secondCaption [i+1], thirdCaption [i+1], fourthCaption [i+1],fifthCaption [i+1],sixthCaption [i+1], seventhCaption [i+1], eighthCaption [i+1], ninthCaption [i+1],tenthCaption [i+1],\\\n",
    "                        elevenCaption [i+1], twelveCaption [i+1], thirteenCaption [i+1], fourteenCaption [i+1],fifteenCaption [i+1]))\n",
    "    dist = np.linalg.norm(image1 - image2)  \n",
    "    # calculating Euclidean distance using linalg.norm()\n",
    "\n",
    "  euclidList.append(dist)\n",
    " \n",
    "# printing Euclidean distance\n",
    "print(f\"Length: {len(euclidList)} \")\n",
    "\n",
    "#********************************************************************************\n",
    "# process the input image data into a list with 0, 1 act as the boundaries\n",
    "\n",
    "boundariesList = []\n",
    "\n",
    "x = len(euclidList)\n",
    "print(f\"\\nNumber of Pics: {num_pics}\")\n",
    "print(f\"Length of List: {x}\" )  \n",
    "for i in range(num_pics):\n",
    "  if euclidList[i] == euclidList[x-1]:    #length count from 1, so need deduct 1\n",
    "    boundariesList.append(0)\n",
    "  elif(abs(euclidList[i]) - (euclidList[i+1]) > 0.40):\n",
    "      boundariesList.append(1)\n",
    "  else:\n",
    "    boundariesList.append(0)\n",
    "\n",
    "for i in range(num_pics):\n",
    "   print(f\"{i+1}. {euclidList[i]} {boundariesList[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Kdvs68ZeeCfM",
   "metadata": {
    "id": "Kdvs68ZeeCfM"
   },
   "outputs": [],
   "source": [
    "# Calculate F-1 \n",
    "\n",
    "# initializations\n",
    "# Compute TP, FP, TN, FN\n",
    "tp = 0; fp = 0; tn = 0; fn = 0;\n",
    "for bi in range(num_pics):\n",
    "    # If actual==1 and pred==1, increment true positives\n",
    "  if (trueboundariesList[bi] == 1) and (boundariesList[bi] == 1):\n",
    "    tp = tp + 1\n",
    "    # If actual==1 and pred==0, increment false negatives\n",
    "  if (trueboundariesList[bi] == 1) and (boundariesList[bi] == 0):\n",
    "    fn = fn + 1\n",
    "    # If actual==0 and pred==1, increment false positives\n",
    "  if (trueboundariesList[bi] == 0) and (boundariesList[bi] == 1):\n",
    "    fp = fp + 1\n",
    "    # If actual==0 and pred==0, increment true negatives\n",
    "  if (trueboundariesList[bi] == 0) and (boundariesList[bi] == 0):\n",
    "    tn = tn + 1\n",
    "\n",
    "# Display tp, fp, tn, fn\n",
    "print('True positives: ', tp)\n",
    "print('False positives: ', fp)\n",
    "print('True negatives: ', tn)\n",
    "print('False negatives: ', fn)\n",
    "\n",
    "# Compute precision and recall\n",
    "denom = (tp + fp)\n",
    "if denom > 0:\n",
    "    precision = tp / denom\n",
    "else:\n",
    "    precision = 0\n",
    "denom = (tp + fn)\n",
    "if denom > 0:\n",
    "    recall = tp / denom\n",
    "else:\n",
    "    recall = 0\n",
    "# Compute F1 score\n",
    "\n",
    "denom = (precision+recall)\n",
    "if denom > 0:\n",
    "    f1 = 2 * ((precision*recall)/denom)\n",
    "else:\n",
    "    f1 = 0\n",
    "# Return all metrics\n",
    "res = {\n",
    "        'tp': tp,\n",
    "        'fp': fp,\n",
    "        'tn': tn,\n",
    "        'fn': fn,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "}\n",
    "\n",
    "print(res)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "B27JyPPfeDw-",
   "metadata": {
    "id": "B27JyPPfeDw-"
   },
   "outputs": [],
   "source": [
    "# this block of code is to add loop to find the best value for boundaries\n",
    "\n",
    "o = 0.00\n",
    "o_list = []\n",
    "f1_list = []\n",
    "\n",
    "while o <= 1.00:\n",
    "\n",
    "  boundariesList = []\n",
    "\n",
    "  x = len(euclidList)\n",
    "  #print(f\"\\nNumber of Pics: {num_pics}\")\n",
    "  #print(f\"Length of List: {x}\" )  \n",
    "  for i in range(num_pics):\n",
    "    if euclidList[i] == euclidList[x-1]:    #length count from 1, so need deduct 1\n",
    "      boundariesList.append(0)\n",
    "    elif(abs(euclidList[i]) - (euclidList[i+1]) >= o):\n",
    "        boundariesList.append(1)\n",
    "    else:\n",
    "      boundariesList.append(0)\n",
    "\n",
    "  #for i in range(num_pics):\n",
    "    #print(f\"{i+1}. {euclidList[i]} {boundariesList[i]}\")\n",
    "\n",
    "  ################################################################\n",
    "    tp = 0; fp = 0; tn = 0; fn = 0;\n",
    "  for bi in range(num_pics):\n",
    "      # If actual==1 and pred==1, increment true positives\n",
    "    if (trueboundariesList[bi] == 1) and (boundariesList[bi] == 1):\n",
    "      tp = tp + 1\n",
    "      # If actual==1 and pred==0, increment false negatives\n",
    "    if (trueboundariesList[bi] == 1) and (boundariesList[bi] == 0):\n",
    "      fn = fn + 1\n",
    "      # If actual==0 and pred==1, increment false positives\n",
    "    if (trueboundariesList[bi] == 0) and (boundariesList[bi] == 1):\n",
    "      fp = fp + 1\n",
    "      # If actual==0 and pred==0, increment true negatives\n",
    "    if (trueboundariesList[bi] == 0) and (boundariesList[bi] == 0):\n",
    "      tn = tn + 1\n",
    "\n",
    "\n",
    "  # Compute precision and recall\n",
    "  denom = (tp + fp)\n",
    "  if denom > 0:\n",
    "      precision = tp / denom\n",
    "  else:\n",
    "      precision = 0\n",
    "  denom = (tp + fn)\n",
    "  if denom > 0:\n",
    "      recall = tp / denom\n",
    "  else:\n",
    "      recall = 0\n",
    "  # Compute F1 score\n",
    "\n",
    "  denom = (precision+recall)\n",
    "  if denom > 0:\n",
    "      f1 = 2 * ((precision*recall)/denom)\n",
    "  else:\n",
    "      f1 = 0\n",
    "  # Return all metrics\n",
    "  res = {\n",
    "          'tp': tp,\n",
    "          'fp': fp,\n",
    "          'tn': tn,\n",
    "          'fn': fn,\n",
    "          'precision': precision,\n",
    "          'recall': recall,\n",
    "          'f1': f1\n",
    "  }\n",
    "  o_list.append(o)\n",
    "  f1_list.append(res['f1'])\n",
    "  o += 0.05\n",
    "\n",
    "print(o_list)\n",
    "print(f1_list)\n",
    "#*******************************************************************\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(o_list, f1_list)\n",
    "plt.xlabel(\"Diff_value (O)\")\n",
    "plt.ylabel(\"F1-score\")\n",
    "plt.xlim(0, 1.00)\n",
    "plt.ylim(0, 1.00)\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ItoTTUgrvpZa",
   "metadata": {
    "id": "ItoTTUgrvpZa"
   },
   "source": [
    "# Experiment 3.4 - CLIP's image encoder embedding space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BKDNIR0_bWl9",
   "metadata": {
    "id": "BKDNIR0_bWl9"
   },
   "source": [
    "This experiment is using CLIP's image encoder embedding space for comparison purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Yl930P7rvqud",
   "metadata": {
    "id": "Yl930P7rvqud"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "import os\n",
    "from PIL import Image\n",
    "import array as arr \n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model, preprocess = clip.load(\"ViT-L/14@336px\", device=device)\n",
    "\n",
    "source_path = '/content/gdrive/MyDrive/Colab Notebooks/data-1/imgs/'\n",
    "dir_contents = os.listdir(source_path) # returns list\n",
    "dir_contents.sort()\n",
    "num_pics = len(dir_contents)   # find number of pictures in directory\n",
    "print(num_pics)\n",
    "\n",
    "images = []\n",
    "image_features = []\n",
    "for i in range(num_pics):\n",
    "#Load and prepare images\n",
    "  image_path = os.path.join(source_path, dir_contents[i])\n",
    "  image = preprocess(Image.open(image_path)).unsqueeze(0).to(device)\n",
    "  images.append(image)\n",
    "\n",
    "  with torch.no_grad():\n",
    "    features = model.encode_image(image)\n",
    "    features /= features.norm(dim=-1, keepdim=True)\n",
    "    image_features.append(features)\n",
    "\n",
    "similarities = []\n",
    "\n",
    "# saved the similarity of image features on adjacent images in similarities list\n",
    "for i in range(num_pics-1):   #range start from 0\n",
    "    similarity = (100.0 * image_features[i] @ image_features[i+1].T).item()\n",
    "    similarities.append(similarity)\n",
    "\n",
    "# as here compute difference only so at the end will get num_pics - 1, so I add the last 1\n",
    "x = len(similarities)\n",
    "similarities.append(similarities[x-1])\n",
    "\n",
    "print(similarities)\n",
    "print(len(similarities))\n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DPTuMc3O_onm",
   "metadata": {
    "id": "DPTuMc3O_onm"
   },
   "outputs": [],
   "source": [
    "# process the input image data into a list with 0, 1 act as the boundaries\n",
    "\n",
    "boundariesList = []\n",
    "x = len(similarities)\n",
    "print(f\"\\nNumber of Pics: {num_pics}\")\n",
    "print(f\"Length of List: {x}\" )  \n",
    "for i in range(num_pics):\n",
    "  if similarities[i] == similarities[x-1]:    #length count from 1, so need deduct 1\n",
    "    boundariesList.append(0)\n",
    "  elif(similarities[i]  < 88):\n",
    "      boundariesList.append(1)\n",
    "  else:\n",
    "    boundariesList.append(0)\n",
    "\n",
    "for i in range(num_pics):\n",
    "   print(f\"{i+1}. Image{i+1} {boundariesList[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Y5DliJUhCVnw",
   "metadata": {
    "id": "Y5DliJUhCVnw"
   },
   "outputs": [],
   "source": [
    "# Processing the actual boundaries file\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "boundaries_path_file = \"/content/gdrive/MyDrive/Colab Notebooks/data-1/Boundaries.txt\"\n",
    "boundaries_df = pd.read_csv(boundaries_path_file)\n",
    "bound_strings = boundaries_df.columns.tolist()\n",
    "num_bound = len(bound_strings)\n",
    "bound_int = []\n",
    "\n",
    "#convert string list to int list\n",
    "for i in range(0,len(bound_strings)):\n",
    "    bound_strings[i] = int(bound_strings[i])\n",
    "\n",
    "trueboundariesList = []\n",
    "\n",
    "\n",
    "for j in range(num_pics):                 # num_pics = 273\n",
    "  if j == bound_strings[num_bound -1]:    # -1 cause j start from 0, when 34 meet 34 is last\n",
    "      trueboundariesList.append(0)\n",
    "  elif any(j +1 == y  for y in bound_strings):\n",
    "    trueboundariesList.append(1)\n",
    "  else:\n",
    "     trueboundariesList.append(0)\n",
    "\n",
    "for i in range(num_pics):\n",
    "   print(f\"{i+1}. {trueboundariesList[i]} {boundariesList[i]}\")\n",
    "\n",
    "# there are 35 of boundaries detected, which match with the Boundaries.txt for data-1\n",
    "count = len([elem for elem in trueboundariesList if elem == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ckVQ-uTeCb0_",
   "metadata": {
    "id": "ckVQ-uTeCb0_"
   },
   "outputs": [],
   "source": [
    "# Calculate F-1 \n",
    "\n",
    "# initializations\n",
    "# Compute TP, FP, TN, FN\n",
    "tp = 0; fp = 0; tn = 0; fn = 0;\n",
    "for bi in range(num_pics):\n",
    "    # If actual==1 and pred==1, increment true positives\n",
    "  if (trueboundariesList[bi] == 1) and (boundariesList[bi] == 1):\n",
    "    tp = tp + 1\n",
    "    # If actual==1 and pred==0, increment false negatives\n",
    "  if (trueboundariesList[bi] == 1) and (boundariesList[bi] == 0):\n",
    "    fn = fn + 1\n",
    "    # If actual==0 and pred==1, increment false positives\n",
    "  if (trueboundariesList[bi] == 0) and (boundariesList[bi] == 1):\n",
    "    fp = fp + 1\n",
    "    # If actual==0 and pred==0, increment true negatives\n",
    "  if (trueboundariesList[bi] == 0) and (boundariesList[bi] == 0):\n",
    "    tn = tn + 1\n",
    "\n",
    "# Display tp, fp, tn, fn\n",
    "print('True positives: ', tp)\n",
    "print('False positives: ', fp)\n",
    "print('True negatives: ', tn)\n",
    "print('False negatives: ', fn)\n",
    "\n",
    "# Compute precision and recall\n",
    "denom = (tp + fp)\n",
    "if denom > 0:\n",
    "    precision = tp / denom\n",
    "else:\n",
    "    precision = 0\n",
    "denom = (tp + fn)\n",
    "if denom > 0:\n",
    "    recall = tp / denom\n",
    "else:\n",
    "    recall = 0\n",
    "# Compute F1 score\n",
    "\n",
    "denom = (precision+recall)\n",
    "if denom > 0:\n",
    "    f1 = 2 * ((precision*recall)/denom)\n",
    "else:\n",
    "    f1 = 0\n",
    "# Return all metrics\n",
    "res = {\n",
    "        'tp': tp,\n",
    "        'fp': fp,\n",
    "        'tn': tn,\n",
    "        'fn': fn,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "}\n",
    "\n",
    "print(res)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1DzPFbLdb7_h",
   "metadata": {
    "id": "1DzPFbLdb7_h"
   },
   "source": [
    "Find the best value for threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-I0bZb6hCoNt",
   "metadata": {
    "id": "-I0bZb6hCoNt"
   },
   "outputs": [],
   "source": [
    "o = 0.00\n",
    "o_list = []\n",
    "f1_list = []\n",
    "\n",
    "while o <= 100.00:\n",
    "\n",
    "  boundariesList = []\n",
    "  x = len(similarities)\n",
    "  for i in range(num_pics):\n",
    "    if similarities[i] == similarities[x-1]:    #length count from 1, so need deduct 1\n",
    "      boundariesList.append(0)\n",
    "    elif(similarities[i]  < o):\n",
    "        boundariesList.append(1)\n",
    "    else:\n",
    "      boundariesList.append(0)\n",
    "\n",
    "  ################################################################\n",
    "    tp = 0; fp = 0; tn = 0; fn = 0;\n",
    "  for bi in range(num_pics):\n",
    "      # If actual==1 and pred==1, increment true positives\n",
    "    if (trueboundariesList[bi] == 1) and (boundariesList[bi] == 1):\n",
    "      tp = tp + 1\n",
    "      # If actual==1 and pred==0, increment false negatives\n",
    "    if (trueboundariesList[bi] == 1) and (boundariesList[bi] == 0):\n",
    "      fn = fn + 1\n",
    "      # If actual==0 and pred==1, increment false positives\n",
    "    if (trueboundariesList[bi] == 0) and (boundariesList[bi] == 1):\n",
    "      fp = fp + 1\n",
    "      # If actual==0 and pred==0, increment true negatives\n",
    "    if (trueboundariesList[bi] == 0) and (boundariesList[bi] == 0):\n",
    "      tn = tn + 1\n",
    "\n",
    "\n",
    "  # Compute precision and recall\n",
    "  denom = (tp + fp)\n",
    "  if denom > 0:\n",
    "      precision = tp / denom\n",
    "  else:\n",
    "      precision = 0\n",
    "  denom = (tp + fn)\n",
    "  if denom > 0:\n",
    "      recall = tp / denom\n",
    "  else:\n",
    "      recall = 0\n",
    "  # Compute F1 score\n",
    "\n",
    "  denom = (precision+recall)\n",
    "  if denom > 0:\n",
    "      f1 = 2 * ((precision*recall)/denom)\n",
    "  else:\n",
    "      f1 = 0\n",
    "  # Return all metrics\n",
    "  res = {\n",
    "          'tp': tp,\n",
    "          'fp': fp,\n",
    "          'tn': tn,\n",
    "          'fn': fn,\n",
    "          'precision': precision,\n",
    "          'recall': recall,\n",
    "          'f1': f1\n",
    "  }\n",
    "  o_list.append(o)\n",
    "  f1_list.append(res['f1'])\n",
    "  o += 1.00\n",
    "\n",
    "\n",
    "print(o_list)\n",
    "print(f1_list)\n",
    "\n",
    "a = (max(f1_list))\n",
    "print(f1_list.index(a))\n",
    "print(a)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uX9AfQdeFITz",
   "metadata": {
    "id": "uX9AfQdeFITz"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(o_list, f1_list)\n",
    "plt.xlabel(\"Diff_value (O)\")\n",
    "plt.ylabel(\"F1-score\")\n",
    "plt.xlim(0, 100.00)\n",
    "plt.ylim(0, 1.00)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ywTqJhLcHIg6",
   "metadata": {
    "id": "ywTqJhLcHIg6"
   },
   "source": [
    "# Experiment 3.5 - Distance Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cZNR_Kvnjp",
   "metadata": {
    "id": "74cZNR_Kvnjp"
   },
   "source": [
    "Explore the impact of using different distance metrics such as Manhattan distance, Minkowski distance and Cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cGe3KV0vxwM",
   "metadata": {
    "id": "8cGe3KV0vxwM"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "import os\n",
    "from PIL import Image\n",
    "import array as arr \n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# some initial set up\n",
    "with open('/content/gdrive/MyDrive/Colab Notebooks/insectDomainClass.txt') as f:\n",
    "    image_descriptions = [line.rstrip() for line in f]\n",
    "\n",
    "model, preprocess = clip.load(\"ViT-L/14@336px\", device=device)\n",
    "source_path = '/content/gdrive/MyDrive/Colab Notebooks/data-1/imgs/'\n",
    "dir_contents = os.listdir(source_path) \n",
    "dir_contents.sort()\n",
    "num_pics = len(dir_contents)   \n",
    "\n",
    "# Here convert list into dictionary with 'int' as key\n",
    "list1 = list(range(1,len(image_descriptions)+1))\n",
    "list2 = []\n",
    "\n",
    "# here append queries into list\n",
    "for c in image_descriptions:\n",
    "  list2.append(c)\n",
    "\n",
    "class_dictionary = dict(zip(list1, list2))\n",
    "print(class_dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SrzCGCrTv0sJ",
   "metadata": {
    "id": "SrzCGCrTv0sJ"
   },
   "outputs": [],
   "source": [
    "# Processing the actual boundaries file\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "boundaries_path_file = \"/content/gdrive/MyDrive/Colab Notebooks/data-1/Boundaries.txt\"\n",
    "boundaries_df = pd.read_csv(boundaries_path_file)\n",
    "bound_strings = boundaries_df.columns.tolist()\n",
    "num_bound = len(bound_strings)\n",
    "bound_int = []\n",
    "\n",
    "#convert string list to int list\n",
    "for i in range(0,len(bound_strings)):\n",
    "    bound_strings[i] = int(bound_strings[i])\n",
    "\n",
    "trueboundariesList = []\n",
    "\n",
    "\n",
    "for j in range(num_pics):                 # num_pics = 273\n",
    "  if j == bound_strings[num_bound -1]:    # -1 cause j start from 0, when 34 meet 34 is last\n",
    "      trueboundariesList.append(0)\n",
    "  elif any(j +1 == y  for y in bound_strings):\n",
    "    trueboundariesList.append(1)\n",
    "  else:\n",
    "     trueboundariesList.append(0)\n",
    "\n",
    "for i in range(num_pics):\n",
    "   print(f\"{i+1}. {trueboundariesList[i]}\")\n",
    "\n",
    "# there are 35 of boundaries detected, which match with the Boundaries.txt for data-1\n",
    "count = len([elem for elem in trueboundariesList if elem == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fvAJpurmHK1L",
   "metadata": {
    "id": "fvAJpurmHK1L"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "import os\n",
    "from PIL import Image\n",
    "import array as arr \n",
    "\n",
    "resultList = []\n",
    "firstCaption = []\n",
    "secondCaption = []\n",
    "thirdCaption = []\n",
    "fourthCaption = []\n",
    "fifthCaption = []\n",
    "sixthCaption = []\n",
    "seventhCaption = []\n",
    "eighthCaption = []\n",
    "ninthCaption = []\n",
    "tenthCaption = []\n",
    "\n",
    "elevenCaption = []\n",
    "twelveCaption = []\n",
    "thirteenCaption = []\n",
    "fourteenCaption = []\n",
    "fifteenCaption = []\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model, preprocess = clip.load(\"ViT-L/14@336px\", device=device)\n",
    "caption = [\"scorpion\",\"angel insects\",\"heelwalker\",\"lacewing\",\"booklice\",\"flea\"\n",
    ",\"stonefly\",\"thrips\",\"true bug\",\"ice crawler\",\"harvestmen\",\"webspinner\",\"earwig\",\"katydid\",\"cricket\"]\n",
    "caption.sort()  # sort captions in alphabetical order\n",
    "\n",
    "\n",
    "for i in range(num_pics):\n",
    "#Load and prepare images\n",
    "  print(\"\\nImage Title: \",dir_contents[i]);\n",
    "  image = preprocess(Image.open(source_path + dir_contents[i])).unsqueeze(0).to(device)\n",
    "  caption_inputs = torch.cat([clip.tokenize(f\"a photo of a {c}\") for c in caption]).to(device)\n",
    " \n",
    "  with torch.no_grad():\n",
    "      image_features = model.encode_image(image)\n",
    "      text_features = model.encode_text(caption_inputs)\n",
    "\n",
    "  image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "  text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "  similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "  #values, indices = similarity[0].topk(10, sorted = False)\n",
    "  values, indices = similarity[0].topk(15, sorted = False)\n",
    "\n",
    "  # Create a list of tuples containing the caption and its corresponding score\n",
    "  captions_and_scores = [(caption[idx], values[idx].item()) for idx in indices]\n",
    "  # Sort the list based on the original order of the captions\n",
    "  captions_and_scores.sort(key=lambda x: caption.index(x[0]))\n",
    "\n",
    "  firstCaption.append(captions_and_scores[0][1])\n",
    "  secondCaption.append(captions_and_scores[1][1])\n",
    "  thirdCaption.append(captions_and_scores[2][1])\n",
    "  fourthCaption.append(captions_and_scores[3][1])\n",
    "  fifthCaption.append(captions_and_scores[4][1])\n",
    "  sixthCaption.append(captions_and_scores[5][1])\n",
    "  seventhCaption.append(captions_and_scores[6][1])\n",
    "  eighthCaption.append(captions_and_scores[7][1])\n",
    "  ninthCaption.append(captions_and_scores[8][1])\n",
    "  tenthCaption.append(captions_and_scores[9][1])\n",
    "\n",
    "  elevenCaption.append(captions_and_scores[10][1])\n",
    "  twelveCaption.append(captions_and_scores[11][1])\n",
    "  thirteenCaption.append(captions_and_scores[12][1])\n",
    "  fourteenCaption.append(captions_and_scores[13][1])\n",
    "  fifteenCaption.append(captions_and_scores[14][1])\n",
    "\n",
    "  print(\"\\nPredictions:\\n\")\n",
    "  for caption_score in captions_and_scores:\n",
    "      print(f\"{caption_score[0]:>16s}: {caption_score[1]:.8f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zjHD5VSacWvQ",
   "metadata": {
    "id": "zjHD5VSacWvQ"
   },
   "source": [
    "Import the nessearcy libraries for distance metrics and define function for Manhattan distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "U3RkAJScv9Bu",
   "metadata": {
    "id": "U3RkAJScv9Bu"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from scipy.spatial import distance\n",
    "from scipy import spatial\n",
    "\n",
    "def manhattan_distance(point1, point2):\n",
    "    return sum(abs(value1 - value2) for value1, value2 in zip(point1, point2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tL23J06Cchos",
   "metadata": {
    "id": "tL23J06Cchos"
   },
   "source": [
    "Compute the distance here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PHP68eC1v_gU",
   "metadata": {
    "id": "PHP68eC1v_gU"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "euclidList = []\n",
    "x = len(firstCaption)\n",
    "# initializing points in numpy arrays\n",
    "for i in range (num_pics):\n",
    "  if (firstCaption[i] == firstCaption [x -1]) and   (secondCaption [i] ==secondCaption[x-1]) and (thirdCaption [i] ==thirdCaption[x-1]) and \\\n",
    "    (fourthCaption [i] ==fourthCaption[x-1]) and (fifthCaption [i] ==fifthCaption[x-1]) and (sixthCaption [i] == sixthCaption[x-1])\\\n",
    "    and (seventhCaption [i] ==seventhCaption[x-1])and (eighthCaption [i] ==eighthCaption[x-1])and (ninthCaption [i] ==ninthCaption[x-1])\\\n",
    "    and (tenthCaption [i] ==tenthCaption[x-1]) and (elevenCaption[i] == elevenCaption [x -1]) and   (twelveCaption [i] ==twelveCaption[x-1]) \\\n",
    "    and (thirteenCaption [i] ==thirteenCaption[x-1]) and (fourteenCaption [i] ==fourteenCaption[x-1]) and (fifteenCaption [i] ==fifteenCaption[x-1]):\n",
    "    dist = 0.00\n",
    "\n",
    "  else:\n",
    "    image1 = np.array((firstCaption [i], secondCaption [i], thirdCaption [i], fourthCaption [i],fifthCaption [i],sixthCaption [i], seventhCaption [i], eighthCaption [i], ninthCaption [i],tenthCaption [i],\\\n",
    "                       elevenCaption [i], twelveCaption [i], thirteenCaption [i], fourteenCaption [i],fifteenCaption [i]))\n",
    "    image2 = np.array((firstCaption [i+1], secondCaption [i+1], thirdCaption [i+1], fourthCaption [i+1],fifthCaption [i+1],sixthCaption [i+1], seventhCaption [i+1], eighthCaption [i+1], ninthCaption [i+1],tenthCaption [i+1],\\\n",
    "                        elevenCaption [i+1], twelveCaption [i+1], thirteenCaption [i+1], fourteenCaption [i+1],fifteenCaption [i+1]))\n",
    "    \n",
    "    #dist = np.linalg.norm(image1 - image2)  # calculating Euclidean distance\n",
    "    dist = manhattan_distance(image1, image2) #calculate manhattan distance\n",
    "    #dist = distance.minkowski(image1,image2,3) #calculate minkowski distance\n",
    "    #dist =  spatial.distance.cosine(image1,image2) #calculate consine similarity\n",
    "  euclidList.append(dist)\n",
    " \n",
    "# printing Euclidean distance\n",
    "print(f\"Length: {len(euclidList)} \")\n",
    "\n",
    "#********************************************************************************\n",
    "# process the input image data into a list with 0, 1 act as the boundaries\n",
    "\n",
    "boundariesList = []\n",
    "\n",
    "x = len(euclidList)\n",
    "print(f\"\\nNumber of Pics: {num_pics}\")\n",
    "print(f\"Length of List: {x}\" )  \n",
    "for i in range(num_pics):\n",
    "  if euclidList[i] == euclidList[x-1]:    #length count from 1, so need deduct 1\n",
    "    boundariesList.append(0)\n",
    "  elif(abs(euclidList[i]) - (euclidList[i+1]) > 0.70):\n",
    "      boundariesList.append(1)\n",
    "  else:\n",
    "    boundariesList.append(0)\n",
    "\n",
    "for i in range(num_pics):\n",
    "   print(f\"{i+1}. {euclidList[i]} {boundariesList[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FNoj7OBiwDp6",
   "metadata": {
    "id": "FNoj7OBiwDp6"
   },
   "outputs": [],
   "source": [
    "# Calculate F-1 \n",
    "\n",
    "# initializations\n",
    "# Compute TP, FP, TN, FN\n",
    "tp = 0; fp = 0; tn = 0; fn = 0;\n",
    "for bi in range(num_pics):\n",
    "    # If actual==1 and pred==1, increment true positives\n",
    "  if (trueboundariesList[bi] == 1) and (boundariesList[bi] == 1):\n",
    "    tp = tp + 1\n",
    "    # If actual==1 and pred==0, increment false negatives\n",
    "  if (trueboundariesList[bi] == 1) and (boundariesList[bi] == 0):\n",
    "    fn = fn + 1\n",
    "    # If actual==0 and pred==1, increment false positives\n",
    "  if (trueboundariesList[bi] == 0) and (boundariesList[bi] == 1):\n",
    "    fp = fp + 1\n",
    "    # If actual==0 and pred==0, increment true negatives\n",
    "  if (trueboundariesList[bi] == 0) and (boundariesList[bi] == 0):\n",
    "    tn = tn + 1\n",
    "\n",
    "# Display tp, fp, tn, fn\n",
    "print('True positives: ', tp)\n",
    "print('False positives: ', fp)\n",
    "print('True negatives: ', tn)\n",
    "print('False negatives: ', fn)\n",
    "\n",
    "# Compute precision and recall\n",
    "denom = (tp + fp)\n",
    "if denom > 0:\n",
    "    precision = tp / denom\n",
    "else:\n",
    "    precision = 0\n",
    "denom = (tp + fn)\n",
    "if denom > 0:\n",
    "    recall = tp / denom\n",
    "else:\n",
    "    recall = 0\n",
    "# Compute F1 score\n",
    "\n",
    "denom = (precision+recall)\n",
    "if denom > 0:\n",
    "    f1 = 2 * ((precision*recall)/denom)\n",
    "else:\n",
    "    f1 = 0\n",
    "# Return all metrics\n",
    "res = {\n",
    "        'tp': tp,\n",
    "        'fp': fp,\n",
    "        'tn': tn,\n",
    "        'fn': fn,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "}\n",
    "\n",
    "print(res)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NBQ0gW3dcomU",
   "metadata": {
    "id": "NBQ0gW3dcomU"
   },
   "source": [
    "Perform threshold optimisation to find the best threshold value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "t5AX_6wBwIRs",
   "metadata": {
    "id": "t5AX_6wBwIRs"
   },
   "outputs": [],
   "source": [
    "o = 0.00\n",
    "o_list = []\n",
    "f1_list = []\n",
    "\n",
    "while o <= 1.00:\n",
    "\n",
    "  boundariesList = []\n",
    "\n",
    "  x = len(euclidList)\n",
    "  #print(f\"\\nNumber of Pics: {num_pics}\")\n",
    "  #print(f\"Length of List: {x}\" )  \n",
    "  for i in range(num_pics):\n",
    "    if euclidList[i] == euclidList[x-1]:    #length count from 1, so need deduct 1\n",
    "      boundariesList.append(0)\n",
    "    elif(abs(euclidList[i]) - (euclidList[i+1]) >= o):\n",
    "        boundariesList.append(1)\n",
    "    else:\n",
    "      boundariesList.append(0)\n",
    "\n",
    "################################################################\n",
    "    tp = 0; fp = 0; tn = 0; fn = 0;\n",
    "  for bi in range(num_pics):\n",
    "      # If actual==1 and pred==1, increment true positives\n",
    "    if (trueboundariesList[bi] == 1) and (boundariesList[bi] == 1):\n",
    "      tp = tp + 1\n",
    "      # If actual==1 and pred==0, increment false negatives\n",
    "    if (trueboundariesList[bi] == 1) and (boundariesList[bi] == 0):\n",
    "      fn = fn + 1\n",
    "      # If actual==0 and pred==1, increment false positives\n",
    "    if (trueboundariesList[bi] == 0) and (boundariesList[bi] == 1):\n",
    "      fp = fp + 1\n",
    "      # If actual==0 and pred==0, increment true negatives\n",
    "    if (trueboundariesList[bi] == 0) and (boundariesList[bi] == 0):\n",
    "      tn = tn + 1\n",
    "\n",
    "\n",
    "  # Compute precision and recall\n",
    "  denom = (tp + fp)\n",
    "  if denom > 0:\n",
    "      precision = tp / denom\n",
    "  else:\n",
    "      precision = 0\n",
    "  denom = (tp + fn)\n",
    "  if denom > 0:\n",
    "      recall = tp / denom\n",
    "  else:\n",
    "      recall = 0\n",
    "  # Compute F1 score\n",
    "\n",
    "  denom = (precision+recall)\n",
    "  if denom > 0:\n",
    "      f1 = 2 * ((precision*recall)/denom)\n",
    "  else:\n",
    "      f1 = 0\n",
    "  # Return all metrics\n",
    "  res = {\n",
    "          'tp': tp,\n",
    "          'fp': fp,\n",
    "          'tn': tn,\n",
    "          'fn': fn,\n",
    "          'precision': precision,\n",
    "          'recall': recall,\n",
    "          'f1': f1\n",
    "  }\n",
    "  o_list.append(o)\n",
    "  f1_list.append(res['f1'])\n",
    "  o += 0.05\n",
    "\n",
    "print(o_list)\n",
    "print(f1_list)\n",
    "#*******************************************************************\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(o_list, f1_list)\n",
    "plt.xlabel(\"Diff_value (O)\")\n",
    "plt.ylabel(\"F1-score\")\n",
    "plt.xlim(0, 1.00)\n",
    "plt.ylim(0, 1.00)\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cUhpyk7ezrFp",
   "metadata": {
    "id": "cUhpyk7ezrFp"
   },
   "source": [
    "# Experiment 3.6 - Scaling up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5Z_bnq7A2S8Z",
   "metadata": {
    "id": "5Z_bnq7A2S8Z"
   },
   "source": [
    "Use the best set of queries and optimal model to test on other 10 folders. (Excluding the first folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j-ZOwVBOqfJR",
   "metadata": {
    "id": "j-ZOwVBOqfJR"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "import os\n",
    "from PIL import Image\n",
    "import array as arr \n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# some initial set up\n",
    "with open('/content/gdrive/MyDrive/Colab Notebooks/insectDomainClass.txt') as f:\n",
    "    image_descriptions = [line.rstrip() for line in f]\n",
    "\n",
    "model, preprocess = clip.load(\"ViT-L/14@336px\", device=device)\n",
    "\n",
    "# Here convert list into dictionary with 'int' as key\n",
    "list1 = list(range(1,len(image_descriptions)+1))\n",
    "list2 = []\n",
    "\n",
    "# here append queries into list\n",
    "for c in image_descriptions:\n",
    "  list2.append(c)\n",
    "\n",
    "class_dictionary = dict(zip(list1, list2))\n",
    "print(class_dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "i9xNeO17bcQg",
   "metadata": {
    "id": "i9xNeO17bcQg"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def manhattan_distance(point1, point2):\n",
    "    return sum(abs(value1 - value2) for value1, value2 in zip(point1, point2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "B4lqC2kV23-G",
   "metadata": {
    "id": "B4lqC2kV23-G"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "import os\n",
    "from PIL import Image\n",
    "import array as arr \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "counter = 2\n",
    "totalImageCounter = 0\n",
    "totaltp = 0\n",
    "totalfp = 0\n",
    "totaltn = 0\n",
    "totalfn = 0\n",
    "\n",
    "while counter <= 11:\n",
    "  \n",
    "  #*****************************************************************************\n",
    "  base_path = '/content/gdrive/MyDrive/Colab Notebooks/'\n",
    "  dir_name_prefix = 'data-'\n",
    "  dir_name_suffix1 = '/imgs/'\n",
    "\n",
    "  source_path = []\n",
    "  source_path = base_path + dir_name_prefix + str(counter) + dir_name_suffix1\n",
    "\n",
    "  dir_contents = os.listdir(source_path) \n",
    "  dir_contents.sort()\n",
    "  num_pics = len(dir_contents) \n",
    "  print(f\"Folder{counter} got {num_pics} images\")\n",
    "\n",
    "  #********************************************************************************\n",
    "  # Processing the actual boundaries file\n",
    "\n",
    "  dir_name_suffix2 = '/Boundaries.txt'\n",
    "\n",
    "  boundaries_path_file = base_path + dir_name_prefix + str(counter) + dir_name_suffix2\n",
    "\n",
    "  boundaries_df = pd.read_csv(boundaries_path_file)\n",
    "  bound_strings = boundaries_df.columns.tolist()\n",
    "  num_bound = len(bound_strings)\n",
    "  bound_int = []\n",
    "\n",
    "  #convert string list to int list\n",
    "  for i in range(0,len(bound_strings)):\n",
    "      bound_strings[i] = int(bound_strings[i])\n",
    "\n",
    "  trueboundariesList = []\n",
    "\n",
    "\n",
    "  for j in range(num_pics):                 \n",
    "    if j == bound_strings[num_bound -1]:    \n",
    "        trueboundariesList.append(0)\n",
    "    elif any(j +1 == y  for y in bound_strings):\n",
    "      trueboundariesList.append(1)\n",
    "    else:\n",
    "      trueboundariesList.append(0)\n",
    "\n",
    "  count = len([elem for elem in trueboundariesList if elem == 1])\n",
    "\n",
    "  #********************************************************************************\n",
    "\n",
    "  resultList = []\n",
    "  firstCaption = []\n",
    "  secondCaption = []\n",
    "  thirdCaption = []\n",
    "  fourthCaption = []\n",
    "  fifthCaption = []\n",
    "  sixthCaption = []\n",
    "  seventhCaption = []\n",
    "  eighthCaption = []\n",
    "  ninthCaption = []\n",
    "  tenthCaption = []\n",
    "\n",
    "  elevenCaption = []\n",
    "  twelveCaption = []\n",
    "  thirteenCaption = []\n",
    "  fourteenCaption = []\n",
    "  fifteenCaption = []\n",
    "\n",
    "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "  model, preprocess = clip.load(\"ViT-L/14@336px\", device=device)\n",
    "  caption = [\"scorpion\",\"angel insects\",\"heelwalker\",\"lacewing\",\"booklice\",\"flea\"\n",
    "  ,\"stonefly\",\"thrips\",\"true bug\",\"ice crawler\",\"harvestmen\",\"webspinner\",\"earwig\",\"katydid\",\"cricket\"]\n",
    "  caption.sort()  # sort captions in alphabetical order\n",
    "\n",
    "\n",
    "  for i in range(num_pics):\n",
    "  #Load and prepare images\n",
    "    #print(\"\\nImage Title: \",dir_contents[i]);\n",
    "    image = preprocess(Image.open(source_path + dir_contents[i])).unsqueeze(0).to(device)\n",
    "    caption_inputs = torch.cat([clip.tokenize(f\"a photo of a {c}\") for c in caption]).to(device)\n",
    "  \n",
    "    with torch.no_grad():\n",
    "        image_features = model.encode_image(image)\n",
    "        text_features = model.encode_text(caption_inputs)\n",
    "\n",
    "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "    similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "    values, indices = similarity[0].topk(15, sorted = False)\n",
    "\n",
    "    # Create a list of tuples containing the caption and its corresponding score\n",
    "    captions_and_scores = [(caption[idx], values[idx].item()) for idx in indices]\n",
    "    # Sort the list based on the original order of the captions\n",
    "    captions_and_scores.sort(key=lambda x: caption.index(x[0]))\n",
    "\n",
    "    firstCaption.append(captions_and_scores[0][1])\n",
    "    secondCaption.append(captions_and_scores[1][1])\n",
    "    thirdCaption.append(captions_and_scores[2][1])\n",
    "    fourthCaption.append(captions_and_scores[3][1])\n",
    "    fifthCaption.append(captions_and_scores[4][1])\n",
    "    sixthCaption.append(captions_and_scores[5][1])\n",
    "    seventhCaption.append(captions_and_scores[6][1])\n",
    "    eighthCaption.append(captions_and_scores[7][1])\n",
    "    ninthCaption.append(captions_and_scores[8][1])\n",
    "    tenthCaption.append(captions_and_scores[9][1])\n",
    "\n",
    "    elevenCaption.append(captions_and_scores[10][1])\n",
    "    twelveCaption.append(captions_and_scores[11][1])\n",
    "    thirteenCaption.append(captions_and_scores[12][1])\n",
    "    fourteenCaption.append(captions_and_scores[13][1])\n",
    "    fifteenCaption.append(captions_and_scores[14][1])\n",
    "\n",
    "  #*******************************************************************************\n",
    "  # Calculate Manhattan Distance Here \n",
    "\n",
    "  euclidList = []\n",
    "  x = len(firstCaption)\n",
    "  # initializing points in numpy arrays\n",
    "  for i in range (num_pics):\n",
    "    if (firstCaption[i] == firstCaption [x -1]) and   (secondCaption [i] ==secondCaption[x-1]) and (thirdCaption [i] ==thirdCaption[x-1]) and \\\n",
    "      (fourthCaption [i] ==fourthCaption[x-1]) and (fifthCaption [i] ==fifthCaption[x-1]) and (sixthCaption [i] == sixthCaption[x-1])\\\n",
    "      and (seventhCaption [i] ==seventhCaption[x-1])and (eighthCaption [i] ==eighthCaption[x-1])and (ninthCaption [i] ==ninthCaption[x-1])\\\n",
    "      and (tenthCaption [i] ==tenthCaption[x-1]) and (elevenCaption[i] == elevenCaption [x -1]) and   (twelveCaption [i] ==twelveCaption[x-1]) \\\n",
    "      and (thirteenCaption [i] ==thirteenCaption[x-1]) and (fourteenCaption [i] ==fourteenCaption[x-1]) and (fifteenCaption [i] ==fifteenCaption[x-1]):\n",
    "      dist = 0.00\n",
    "\n",
    "    else:\n",
    "      image1 = np.array((firstCaption [i], secondCaption [i], thirdCaption [i], fourthCaption [i],fifthCaption [i],sixthCaption [i], seventhCaption [i], eighthCaption [i], ninthCaption [i],tenthCaption [i],\\\n",
    "                        elevenCaption [i], twelveCaption [i], thirteenCaption [i], fourteenCaption [i],fifteenCaption [i]))\n",
    "      image2 = np.array((firstCaption [i+1], secondCaption [i+1], thirdCaption [i+1], fourthCaption [i+1],fifthCaption [i+1],sixthCaption [i+1], seventhCaption [i+1], eighthCaption [i+1], ninthCaption [i+1],tenthCaption [i+1],\\\n",
    "                          elevenCaption [i+1], twelveCaption [i+1], thirteenCaption [i+1], fourteenCaption [i+1],fifteenCaption [i+1]))\n",
    "      \n",
    "      dist = manhattan_distance(image1, image2) #calculate manhattan distance\n",
    "    euclidList.append(dist)\n",
    "  \n",
    "\n",
    "  #********************************************************************************\n",
    "  # process the input image data into a list with 0, 1 act as the boundaries\n",
    "\n",
    "  boundariesList = []\n",
    "\n",
    "  x = len(euclidList)\n",
    "\n",
    "  for i in range(num_pics):\n",
    "    if euclidList[i] == euclidList[x-1]:    #length count from 1, so need deduct 1\n",
    "      boundariesList.append(0)\n",
    "    elif(abs(euclidList[i]) - (euclidList[i+1]) > 0.70):\n",
    "        boundariesList.append(1)\n",
    "    else:\n",
    "      boundariesList.append(0)\n",
    "  \n",
    "  #count how many boundary had generated\n",
    "  totalImageCounter += len(boundariesList)\n",
    "\n",
    "  #******************************************************************************\n",
    "  # Calculate F-1 \n",
    "\n",
    "  # initializations\n",
    "  # Compute TP, FP, TN, FN\n",
    "  tp = 0; fp = 0; tn = 0; fn = 0;\n",
    "  for bi in range(num_pics):\n",
    "      # If actual==1 and pred==1, increment true positives\n",
    "    if (trueboundariesList[bi] == 1) and (boundariesList[bi] == 1):\n",
    "      tp = tp + 1\n",
    "      # If actual==1 and pred==0, increment false negatives\n",
    "    if (trueboundariesList[bi] == 1) and (boundariesList[bi] == 0):\n",
    "      fn = fn + 1\n",
    "      # If actual==0 and pred==1, increment false positives\n",
    "    if (trueboundariesList[bi] == 0) and (boundariesList[bi] == 1):\n",
    "      fp = fp + 1\n",
    "      # If actual==0 and pred==0, increment true negatives\n",
    "    if (trueboundariesList[bi] == 0) and (boundariesList[bi] == 0):\n",
    "      tn = tn + 1\n",
    "\n",
    "  # Compute precision and recall\n",
    "  denom = (tp + fp)\n",
    "  if denom > 0:\n",
    "      precision = tp / denom\n",
    "  else:\n",
    "      precision = 0\n",
    "  denom = (tp + fn)\n",
    "  if denom > 0:\n",
    "      recall = tp / denom\n",
    "  else:\n",
    "      recall = 0\n",
    "  # Compute F1 score\n",
    "\n",
    "  denom = (precision+recall)\n",
    "  if denom > 0:\n",
    "      f1 = 2 * ((precision*recall)/denom)\n",
    "  else:\n",
    "      f1 = 0\n",
    "  # Return all metrics\n",
    "  res = {\n",
    "          'tp': tp,\n",
    "          'fp': fp,\n",
    "          'tn': tn,\n",
    "          'fn': fn,\n",
    "          'precision': precision,\n",
    "          'recall': recall,\n",
    "          'f1': f1\n",
    "  }\n",
    "  totaltp = totaltp +tp\n",
    "  totalfp = totalfp +fp\n",
    "  totaltn = totaltn +tn\n",
    "  totalfn = totalfn +fn\n",
    "  print(f\"Folder {counter}: {res}\")\n",
    "  counter += 1\n",
    "\n",
    "print(f\"Total image: {totalImageCounter}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eKNJyH72Wx9j",
   "metadata": {
    "id": "eKNJyH72Wx9j"
   },
   "outputs": [],
   "source": [
    "# Calculate Total F-1 \n",
    "\n",
    "# Compute precision and recall\n",
    "denom = (totaltp + totalfp)\n",
    "if denom > 0:\n",
    "    precision = totaltp / denom\n",
    "else:\n",
    "    precision = 0\n",
    "denom = (totaltp + totalfn)\n",
    "if denom > 0:\n",
    "    recall = totaltp / denom\n",
    "else:\n",
    "    recall = 0\n",
    "# Compute F1 score\n",
    "\n",
    "denom = (precision+recall)\n",
    "if denom > 0:\n",
    "    f1 = 2 * ((precision*recall)/denom)\n",
    "else:\n",
    "    f1 = 0\n",
    "# Return all metrics\n",
    "res = { \n",
    "        'tp': totaltp,\n",
    "        'fp': totalfp,\n",
    "        'tn': totaltn,\n",
    "        'fn': totalfn,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "}\n",
    "\n",
    "print(res)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Vcvj5hwpNBOa",
   "metadata": {
    "id": "Vcvj5hwpNBOa"
   },
   "source": [
    "# Experiment 3.4 + - Scaling up (Image Encoder Embedding Space)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3lV2fZ5aUHnT",
   "metadata": {
    "id": "3lV2fZ5aUHnT"
   },
   "source": [
    "In Experiment 3.4, I only used image-encoder to tested in data-1 images. Here is using from data-2 to data-11 folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5EDqAOHaNPoz",
   "metadata": {
    "id": "5EDqAOHaNPoz"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "import os\n",
    "from PIL import Image\n",
    "import array as arr \n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "model, preprocess = clip.load(\"ViT-L/14@336px\", device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nHtyccclP6Vd",
   "metadata": {
    "id": "nHtyccclP6Vd"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "import os\n",
    "from PIL import Image\n",
    "import array as arr \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "counter = 2\n",
    "totalImageCounter = 0\n",
    "totaltp = 0\n",
    "totalfp = 0\n",
    "totaltn = 0\n",
    "totalfn = 0\n",
    "\n",
    "while counter <= 11:\n",
    "  \n",
    "  #*****************************************************************************\n",
    "  base_path = '/content/gdrive/MyDrive/Colab Notebooks/'\n",
    "  dir_name_prefix = 'data-'\n",
    "  dir_name_suffix1 = '/imgs/'\n",
    "\n",
    "  source_path = []\n",
    "  source_path = base_path + dir_name_prefix + str(counter) + dir_name_suffix1\n",
    "\n",
    "  dir_contents = os.listdir(source_path) \n",
    "  dir_contents.sort()\n",
    "  num_pics = len(dir_contents) \n",
    "  print(f\"Folder{counter} got {num_pics} images\")\n",
    "\n",
    "  #********************************************************************************\n",
    "  # Processing the actual boundaries file\n",
    "\n",
    "  dir_name_suffix2 = '/Boundaries.txt'\n",
    "\n",
    "  boundaries_path_file = base_path + dir_name_prefix + str(counter) + dir_name_suffix2\n",
    "\n",
    "  boundaries_df = pd.read_csv(boundaries_path_file)\n",
    "  bound_strings = boundaries_df.columns.tolist()\n",
    "  num_bound = len(bound_strings)\n",
    "  bound_int = []\n",
    "\n",
    "  #convert string list to int list\n",
    "  for i in range(0,len(bound_strings)):\n",
    "      bound_strings[i] = int(bound_strings[i])\n",
    "\n",
    "  trueboundariesList = []\n",
    "\n",
    "\n",
    "  for j in range(num_pics):                 \n",
    "    if j == bound_strings[num_bound -1]:    \n",
    "        trueboundariesList.append(0)\n",
    "    elif any(j +1 == y  for y in bound_strings):\n",
    "      trueboundariesList.append(1)\n",
    "    else:\n",
    "      trueboundariesList.append(0)\n",
    "\n",
    "  count = len([elem for elem in trueboundariesList if elem == 1])\n",
    "\n",
    "  #********************************************************************************\n",
    "  images = []\n",
    "  image_features = []\n",
    "  for i in range(num_pics):\n",
    "  #Load and prepare images\n",
    "    image_path = os.path.join(source_path, dir_contents[i])\n",
    "    image = preprocess(Image.open(image_path)).unsqueeze(0).to(device)\n",
    "    images.append(image)\n",
    "\n",
    "    with torch.no_grad():\n",
    "      features = model.encode_image(image)\n",
    "      features /= features.norm(dim=-1, keepdim=True)\n",
    "      image_features.append(features)\n",
    "\n",
    "\n",
    "  similarities = []\n",
    "\n",
    "\n",
    "  for i in range(num_pics-1):   #range start from 0\n",
    "      similarity = (100.0 * image_features[i] @ image_features[i+1].T).item()\n",
    "      similarities.append(similarity)\n",
    "\n",
    "  #as here compute difference only so at the end will get num_pics - 1, so I add the last 1\n",
    "  x = len(similarities)\n",
    "  similarities.append(similarities[x-1])\n",
    "\n",
    "\n",
    "  #********************************************************************************\n",
    "  # process the input image data into a list with 0, 1 act as the boundaries\n",
    "\n",
    "  boundariesList = []\n",
    "  x = len(similarities)\n",
    "\n",
    "  for i in range(num_pics):\n",
    "    if similarities[i] == similarities[x-1]:    #length count from 1, so need deduct 1\n",
    "      boundariesList.append(0)\n",
    "    elif(similarities[i]  < 88):\n",
    "        boundariesList.append(1)\n",
    "    else:\n",
    "      boundariesList.append(0)\n",
    "  \n",
    "  totalImageCounter += len(boundariesList)\n",
    "  #for i in range(num_pics):\n",
    "    #print(f\"{i+1}. Image{i+1} {boundariesList[i]}\")\n",
    "\n",
    "  #******************************************************************************\n",
    "  # Calculate F-1 \n",
    "\n",
    "  # initializations\n",
    "  # Compute TP, FP, TN, FN\n",
    "  tp = 0; fp = 0; tn = 0; fn = 0;\n",
    "  for bi in range(num_pics):\n",
    "      # If actual==1 and pred==1, increment true positives\n",
    "    if (trueboundariesList[bi] == 1) and (boundariesList[bi] == 1):\n",
    "      tp = tp + 1\n",
    "      # If actual==1 and pred==0, increment false negatives\n",
    "    if (trueboundariesList[bi] == 1) and (boundariesList[bi] == 0):\n",
    "      fn = fn + 1\n",
    "      # If actual==0 and pred==1, increment false positives\n",
    "    if (trueboundariesList[bi] == 0) and (boundariesList[bi] == 1):\n",
    "      fp = fp + 1\n",
    "      # If actual==0 and pred==0, increment true negatives\n",
    "    if (trueboundariesList[bi] == 0) and (boundariesList[bi] == 0):\n",
    "      tn = tn + 1\n",
    "\n",
    "  # Compute precision and recall\n",
    "  denom = (tp + fp)\n",
    "  if denom > 0:\n",
    "      precision = tp / denom\n",
    "  else:\n",
    "      precision = 0\n",
    "  denom = (tp + fn)\n",
    "  if denom > 0:\n",
    "      recall = tp / denom\n",
    "  else:\n",
    "      recall = 0\n",
    "  # Compute F1 score\n",
    "\n",
    "  denom = (precision+recall)\n",
    "  if denom > 0:\n",
    "      f1 = 2 * ((precision*recall)/denom)\n",
    "  else:\n",
    "      f1 = 0\n",
    "  # Return all metrics\n",
    "  res = {\n",
    "          'tp': tp,\n",
    "          'fp': fp,\n",
    "          'tn': tn,\n",
    "          'fn': fn,\n",
    "          'precision': precision,\n",
    "          'recall': recall,\n",
    "          'f1': f1\n",
    "  }\n",
    "  totaltp = totaltp +tp\n",
    "  totalfp = totalfp +fp\n",
    "  totaltn = totaltn +tn\n",
    "  totalfn = totalfn +fn\n",
    "  print(f\"Folder {counter}: {res}\")\n",
    "  counter += 1\n",
    "\n",
    "print(f\"Total image: {totalImageCounter}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6NOlM3qgUDLI",
   "metadata": {
    "id": "6NOlM3qgUDLI"
   },
   "outputs": [],
   "source": [
    "# Calculate Total F-1 \n",
    "\n",
    "# Compute precision and recall\n",
    "denom = (totaltp + totalfp)\n",
    "if denom > 0:\n",
    "    precision = totaltp / denom\n",
    "else:\n",
    "    precision = 0\n",
    "denom = (totaltp + totalfn)\n",
    "if denom > 0:\n",
    "    recall = totaltp / denom\n",
    "else:\n",
    "    recall = 0\n",
    "# Compute F1 score\n",
    "\n",
    "denom = (precision+recall)\n",
    "if denom > 0:\n",
    "    f1 = 2 * ((precision*recall)/denom)\n",
    "else:\n",
    "    f1 = 0\n",
    "# Return all metrics\n",
    "res = { \n",
    "        'tp': totaltp,\n",
    "        'fp': totalfp,\n",
    "        'tn': totaltn,\n",
    "        'fn': totalfn,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "}\n",
    "\n",
    "print(res)\n",
    " "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
